{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PythonProgrammingNet tutorials NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://pythonprogramming.net/data-analysis-tutorials/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Tokenizing Words and Sentences with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXAMPLE_TEXT = \"Hello Mr. Smith, how are you doing today? The weather is great, and Python is awesome. The sky is pinkish-blue. You shouldn't eat cardboard.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello Mr. Smith, how are you doing today?', 'The weather is great, and Python is awesome.', 'The sky is pinkish-blue.', \"You shouldn't eat cardboard.\"]\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(EXAMPLE_TEXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (.)단위로 split된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Mr.', 'Smith', ',', 'how', 'are', 'you', 'doing', 'today', '?', 'The', 'weather', 'is', 'great', ',', 'and', 'Python', 'is', 'awesome', '.', 'The', 'sky', 'is', 'pinkish-blue', '.', 'You', 'should', \"n't\", 'eat', 'cardboard', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(EXAMPLE_TEXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word단위로 split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Stop words with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 데이터 분석에서 전처리 작업은 필요없는 데이터를 filtering하는 것이다. \n",
    "# 자연어 처리 분야에서 useless data란 stop words이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_sent = \"This is a sample sentence, showing off the stop words filtration.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'sample',\n",
       " 'sentence',\n",
       " ',',\n",
       " 'showing',\n",
       " 'off',\n",
       " 'the',\n",
       " 'stop',\n",
       " 'words',\n",
       " 'filtration',\n",
       " '.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens = word_tokenize(example_sent);word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'sample',\n",
       " 'sentence',\n",
       " ',',\n",
       " 'showing',\n",
       " 'stop',\n",
       " 'words',\n",
       " 'filtration',\n",
       " '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentence = [w for w in word_tokens if not w in stop_words];filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_sentence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sample', 'sentence', ',', 'showing', 'off', 'the', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Stemming words with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stemming = sort of normalizing method\n",
    "# 어간추출, 어간이란 굴절하는 단어에서 변화하지 않는 부분을 의미함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_words = [\"python\",\"pythoner\",\"pythoning\",\"pythoned\",\"pythonly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "python\n",
      "python\n",
      "python\n",
      "pythonli\n"
     ]
    }
   ],
   "source": [
    "for w in example_words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_text = \"It is important to by very pythonly while you are pythoning with python. All pythoners have pythoned poorly at least once.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It\n",
      "is\n",
      "import\n",
      "to\n",
      "by\n",
      "veri\n",
      "pythonli\n",
      "while\n",
      "you\n",
      "are\n",
      "python\n",
      "with\n",
      "python\n",
      ".\n",
      "all\n",
      "python\n",
      "have\n",
      "python\n",
      "poorli\n",
      "at\n",
      "least\n",
      "onc\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(new_text)\n",
    "\n",
    "for w in words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Part of Speech Tagging with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### labeling words in a  sentence as nouns, adjectives, verbs, tense ...etc\n",
    "##### nltk.pos_tag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n이 라이브러리는 다른 데이터로 학습된 pre trained model이다. \\n그러므로 적합한 tokenize를 하기 위해서는 own data를 가지고 학습을 시켜야한다.\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# why do we use PunktSentenceTokenizer?\n",
    "# why do we need two data sets?\n",
    "\"\"\"\n",
    "이 라이브러리는 다른 데이터로 학습된 pre trained model이다. \n",
    "그러므로 적합한 tokenize를 하기 위해서는 own data를 가지고 학습을 시켜야한다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.tokenize.punkt.PunktSentenceTokenizer at 0x1696a3f99e8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"PRESIDENT GEORGE W. BUSH'S ADDRESS BEFORE A JOINT SESSION OF THE CONGRESS ON THE STATE OF THE UNION\\n \\nJanuary 31, 2006\\n\\nTHE PRESIDENT: Thank you all.\",\n",
       " 'Mr. Speaker, Vice President Cheney, members of Congress, members of the Supreme Court and diplomatic corps, distinguished guests, and fellow citizens: Today our nation lost a beloved, graceful, courageous woman who called America to its founding ideals and carried on a noble dream.',\n",
       " 'Tonight we are comforted by the hope of a glad reunion with the husband who was taken so long ago, and we are grateful for the good life of Coretta Scott King.',\n",
       " '(Applause.)',\n",
       " 'President George W. Bush reacts to applause during his State of the Union Address at the Capitol, Tuesday, Jan.',\n",
       " '31, 2006.',\n",
       " \"White House photo by Eric DraperEvery time I'm invited to this rostrum, I'm humbled by the privilege, and mindful of the history we've seen together.\",\n",
       " 'We have gathered under this Capitol dome in moments of national mourning and national achievement.',\n",
       " 'We have served America through one of the most consequential periods of our history -- and it has been my honor to serve with you.',\n",
       " 'In a system of two parties, two chambers, and two elected branches, there will always be differences and debate.',\n",
       " 'But even tough debates can be conducted in a civil tone, and our differences cannot be allowed to harden into anger.',\n",
       " 'To confront the great issues before us, we must act in a spirit of goodwill and respect for one another -- and I will do my part.',\n",
       " 'Tonight the state of our Union is strong -- and together we will make it stronger.',\n",
       " '(Applause.)',\n",
       " 'In this decisive year, you and I will make choices that determine both the future and the character of our country.',\n",
       " 'We will choose to act confidently in pursuing the enemies of freedom -- or retreat from our duties in the hope of an easier life.',\n",
       " 'We will choose to build our prosperity by leading the world economy -- or shut ourselves off from trade and opportunity.',\n",
       " 'In a complex and challenging time, the road of isolationism and protectionism may seem broad and inviting -- yet it ends in danger and decline.',\n",
       " 'The only way to protect our people, the only way to secure the peace, the only way to control our destiny is by our leadership -- so the United States of America will continue to lead.',\n",
       " '(Applause.)',\n",
       " 'Abroad, our nation is committed to an historic, long-term goal -- we seek the end of tyranny in our world.',\n",
       " 'Some dismiss that goal as misguided idealism.',\n",
       " 'In reality, the future security of America depends on it.',\n",
       " 'On September the 11th, 2001, we found that problems originating in a failed and oppressive state 7,000 miles away could bring murder and destruction to our country.',\n",
       " 'Dictatorships shelter terrorists, and feed resentment and radicalism, and seek weapons of mass destruction.',\n",
       " 'Democracies replace resentment with hope, respect the rights of their citizens and their neighbors, and join the fight against terror.',\n",
       " \"Every step toward freedom in the world makes our country safer -- so we will act boldly in freedom's cause.\",\n",
       " '(Applause.)',\n",
       " 'Far from being a hopeless dream, the advance of freedom is the great story of our time.',\n",
       " 'In 1945, there were about two dozen lonely democracies in the world.',\n",
       " 'Today, there are 122.',\n",
       " \"And we're writing a new chapter in the story of self-government -- with women lining up to vote in Afghanistan, and millions of Iraqis marking their liberty with purple ink, and men and women from Lebanon to Egypt debating the rights of individuals and the necessity of freedom.\",\n",
       " 'At the start of 2006, more than half the people of our world live in democratic nations.',\n",
       " 'And we do not forget the other half -- in places like Syria and Burma, Zimbabwe, North Korea, and Iran -- because the demands of justice, and the peace of this world, require their freedom, as well.',\n",
       " '(Applause.)',\n",
       " 'President George W. Bush delivers his State of the Union Address at the Capitol, Tuesday, Jan.',\n",
       " '31, 2006.',\n",
       " 'White House photo by Eric Draper No one can deny the success of freedom, but some men rage and fight against it.',\n",
       " 'And one of the main sources of reaction and opposition is radical Islam -- the perversion by a few of a noble faith into an ideology of terror and death.',\n",
       " 'Terrorists like bin Laden are serious about mass murder -- and all of us must take their declared intentions seriously.',\n",
       " 'They seek to impose a heartless system of totalitarian control throughout the Middle East, and arm themselves with weapons of mass murder.',\n",
       " 'Their aim is to seize power in Iraq, and use it as a safe haven to launch attacks against America and the world.',\n",
       " 'Lacking the military strength to challenge us directly, the terrorists have chosen the weapon of fear.',\n",
       " 'When they murder children at a school in Beslan, or blow up commuters in London, or behead a bound captive, the terrorists hope these horrors will break our will, allowing the violent to inherit the Earth.',\n",
       " 'But they have miscalculated: We love our freedom, and we will fight to keep it.',\n",
       " '(Applause.)',\n",
       " 'In a time of testing, we cannot find security by abandoning our commitments and retreating within our borders.',\n",
       " 'If we were to leave these vicious attackers alone, they would not leave us alone.',\n",
       " 'They would simply move the battlefield to our own shores.',\n",
       " 'There is no peace in retreat.',\n",
       " 'And there is no honor in retreat.',\n",
       " 'By allowing radical Islam to work its will -- by leaving an assaulted world to fend for itself -- we would signal to all that we no longer believe in our own ideals, or even in our own courage.',\n",
       " 'But our enemies and our friends can be certain: The United States will not retreat from the world, and we will never surrender to evil.',\n",
       " '(Applause.)',\n",
       " 'America rejects the false comfort of isolationism.',\n",
       " 'We are the nation that saved liberty in Europe, and liberated death camps, and helped raise up democracies, and faced down an evil empire.',\n",
       " 'Once again, we accept the call of history to deliver the oppressed and move this world toward peace.',\n",
       " 'We remain on the offensive against terror networks.',\n",
       " 'We have killed or captured many of their leaders -- and for the others, their day will come.',\n",
       " 'President George W. Bush greets members of Congress after his State of the Union Address at the Capitol, Tuesday, Jan.',\n",
       " '31, 2006.',\n",
       " 'White House photo by Eric Draper We remain on the offensive in Afghanistan, where a fine President and a National Assembly are fighting terror while building the institutions of a new democracy.',\n",
       " \"We're on the offensive in Iraq, with a clear plan for victory.\",\n",
       " \"First, we're helping Iraqis build an inclusive government, so that old resentments will be eased and the insurgency will be marginalized.\",\n",
       " \"Second, we're continuing reconstruction efforts, and helping the Iraqi government to fight corruption and build a modern economy, so all Iraqis can experience the benefits of freedom.\",\n",
       " \"And, third, we're striking terrorist targets while we train Iraqi forces that are increasingly capable of defeating the enemy.\",\n",
       " 'Iraqis are showing their courage every day, and we are proud to be their allies in the cause of freedom.',\n",
       " '(Applause.)',\n",
       " 'Our work in Iraq is difficult because our enemy is brutal.',\n",
       " 'But that brutality has not stopped the dramatic progress of a new democracy.',\n",
       " 'In less than three years, the nation has gone from dictatorship to liberation, to sovereignty, to a constitution, to national elections.',\n",
       " 'At the same time, our coalition has been relentless in shutting off terrorist infiltration, clearing out insurgent strongholds, and turning over territory to Iraqi security forces.',\n",
       " 'I am confident in our plan for victory; I am confident in the will of the Iraqi people; I am confident in the skill and spirit of our military.',\n",
       " 'Fellow citizens, we are in this fight to win, and we are winning.',\n",
       " '(Applause.)',\n",
       " 'The road of victory is the road that will take our troops home.',\n",
       " 'As we make progress on the ground, and Iraqi forces increasingly take the lead, we should be able to further decrease our troop levels -- but those decisions will be made by our military commanders, not by politicians in Washington, D.C.',\n",
       " '(Applause.)',\n",
       " 'Our coalition has learned from our experience in Iraq.',\n",
       " \"We've adjusted our military tactics and changed our approach to reconstruction.\",\n",
       " 'Along the way, we have benefitted from responsible criticism and counsel offered by members of Congress of both parties.',\n",
       " 'In the coming year, I will continue to reach out and seek your good advice.',\n",
       " 'Yet, there is a difference between responsible criticism that aims for success, and defeatism that refuses to acknowledge anything but failure.',\n",
       " '(Applause.)',\n",
       " 'Hindsight alone is not wisdom, and second-guessing is not a strategy.',\n",
       " '(Applause.)',\n",
       " 'With so much in the balance, those of us in public office have a duty to speak with candor.',\n",
       " 'A sudden withdrawal of our forces from Iraq would abandon our Iraqi allies to death and prison, would put men like bin Laden and Zarqawi in charge of a strategic country, and show that a pledge from America means little.',\n",
       " 'Members of Congress, however we feel about the decisions and debates of the past, our nation has only one option: We must keep our word, defeat our enemies, and stand behind the American military in this vital mission.',\n",
       " '(Applause.)',\n",
       " 'Laura Bush is applauded as she is introduced Tuesday evening, Jan.',\n",
       " '31, 2006 during the State of the Union Address at United States Capitol in Washington.',\n",
       " 'White House photo by Eric Draper Our men and women in uniform are making sacrifices -- and showing a sense of duty stronger than all fear.',\n",
       " \"They know what it's like to fight house to house in a maze of streets, to wear heavy gear in the desert heat, to see a comrade killed by a roadside bomb.\",\n",
       " 'And those who know the costs also know the stakes.',\n",
       " 'Marine Staff Sergeant Dan Clay was killed last month fighting in Fallujah.',\n",
       " 'He left behind a letter to his family, but his words could just as well be addressed to every American.',\n",
       " 'Here is what Dan wrote: \"I know what honor is.',\n",
       " '... It has been an honor to protect and serve all of you.',\n",
       " 'I faced death with the secure knowledge that you would not have to....',\n",
       " 'Never falter!',\n",
       " 'Don\\'t hesitate to honor and support those of us who have the honor of protecting that which is worth protecting.\"',\n",
       " \"Staff Sergeant Dan Clay's wife, Lisa, and his mom and dad, Sara Jo and Bud, are with us this evening.\",\n",
       " 'Welcome.',\n",
       " '(Applause.)',\n",
       " 'Our nation is grateful to the fallen, who live in the memory of our country.',\n",
       " \"We're grateful to all who volunteer to wear our nation's uniform -- and as we honor our brave troops, let us never forget the sacrifices of America's military families.\",\n",
       " '(Applause.)',\n",
       " 'Our offensive against terror involves more than military action.',\n",
       " 'Ultimately, the only way to defeat the terrorists is to defeat their dark vision of hatred and fear by offering the hopeful alternative of political freedom and peaceful change.',\n",
       " 'So the United States of America supports democratic reform across the broader Middle East.',\n",
       " 'Elections are vital, but they are only the beginning.',\n",
       " 'Raising up a democracy requires the rule of law, and protection of minorities, and strong, accountable institutions that last longer than a single vote.',\n",
       " 'The great people of Egypt have voted in a multi-party presidential election -- and now their government should open paths of peaceful opposition that will reduce the appeal of radicalism.',\n",
       " 'The Palestinian people have voted in elections.',\n",
       " 'And now the leaders of Hamas must recognize Israel, disarm, reject terrorism, and work for lasting peace.',\n",
       " '(Applause.)',\n",
       " 'Saudi Arabia has taken the first steps of reform -- now it can offer its people a better future by pressing forward with those efforts.',\n",
       " 'Democracies in the Middle East will not look like our own, because they will reflect the traditions of their own citizens.',\n",
       " 'Yet liberty is the future of every nation in the Middle East, because liberty is the right and hope of all humanity.',\n",
       " '(Applause.)',\n",
       " 'President George W. Bush waves toward the upper visitors gallery of the House Chamber following his State of the Union remarks Tuesday, Jan.',\n",
       " '31, 2006 at the United States Capitol.',\n",
       " 'White House photo by Eric Draper The same is true of Iran, a nation now held hostage by a small clerical elite that is isolating and repressing its people.',\n",
       " 'The regime in that country sponsors terrorists in the Palestinian territories and in Lebanon -- and that must come to an end.',\n",
       " '(Applause.)',\n",
       " 'The Iranian government is defying the world with its nuclear ambitions, and the nations of the world must not permit the Iranian regime to gain nuclear weapons.',\n",
       " '(Applause.)',\n",
       " 'America will continue to rally the world to confront these threats.',\n",
       " 'Tonight, let me speak directly to the citizens of Iran: America respects you, and we respect your country.',\n",
       " 'We respect your right to choose your own future and win your own freedom.',\n",
       " 'And our nation hopes one day to be the closest of friends with a free and democratic Iran.',\n",
       " '(Applause.)',\n",
       " 'To overcome dangers in our world, we must also take the offensive by encouraging economic progress, and fighting disease, and spreading hope in hopeless lands.',\n",
       " 'Isolationism would not only tie our hands in fighting enemies, it would keep us from helping our friends in desperate need.',\n",
       " 'We show compassion abroad because Americans believe in the God-given dignity and worth of a villager with HIV/AIDS, or an infant with malaria, or a refugee fleeing genocide, or a young girl sold into slavery.',\n",
       " 'We also show compassion abroad because regions overwhelmed by poverty, corruption, and despair are sources of terrorism, and organized crime, and human trafficking, and the drug trade.',\n",
       " 'In recent years, you and I have taken unprecedented action to fight AIDS and malaria, expand the education of girls, and reward developing nations that are moving forward with economic and political reform.',\n",
       " 'For people everywhere, the United States is a partner for a better life.',\n",
       " 'Short-changing these efforts would increase the suffering and chaos of our world, undercut our long-term security, and dull the conscience of our country.',\n",
       " 'I urge members of Congress to serve the interests of America by showing the compassion of America.',\n",
       " 'Our country must also remain on the offensive against terrorism here at home.',\n",
       " 'The enemy has not lost the desire or capability to attack us.',\n",
       " 'Fortunately, this nation has superb professionals in law enforcement, intelligence, the military, and homeland security.',\n",
       " 'These men and women are dedicating their lives, protecting us all, and they deserve our support and our thanks.',\n",
       " '(Applause.)',\n",
       " 'They also deserve the same tools they already use to fight drug trafficking and organized crime -- so I ask you to reauthorize the Patriot Act.',\n",
       " '(Applause.)',\n",
       " 'It is said that prior to the attacks of September the 11th, our government failed to connect the dots of the conspiracy.',\n",
       " 'We now know that two of the hijackers in the United States placed telephone calls to al Qaeda operatives overseas.',\n",
       " 'But we did not know about their plans until it was too late.',\n",
       " 'So to prevent another attack -- based on authority given to me by the Constitution and by statute -- I have authorized a terrorist surveillance program to aggressively pursue the international communications of suspected al Qaeda operatives and affiliates to and from America.',\n",
       " 'Previous Presidents have used the same constitutional authority I have, and federal courts have approved the use of that authority.',\n",
       " 'Appropriate members of Congress have been kept informed.',\n",
       " 'The terrorist surveillance program has helped prevent terrorist attacks.',\n",
       " 'It remains essential to the security of America.',\n",
       " 'If there are people inside our country who are talking with al Qaeda, we want to know about it, because we will not sit back and wait to be hit again.',\n",
       " '(Applause.)',\n",
       " 'In all these areas -- from the disruption of terror networks, to victory in Iraq, to the spread of freedom and hope in troubled regions -- we need the support of our friends and allies.',\n",
       " 'To draw that support, we must always be clear in our principles and willing to act.',\n",
       " 'The only alternative to American leadership is a dramatically more dangerous and anxious world.',\n",
       " 'Yet we also choose to lead because it is a privilege to serve the values that gave us birth.',\n",
       " 'American leaders -- from Roosevelt to Truman to Kennedy to Reagan -- rejected isolation and retreat, because they knew that America is always more secure when freedom is on the march.',\n",
       " 'Our own generation is in a long war against a determined enemy -- a war that will be fought by Presidents of both parties, who will need steady bipartisan support from the Congress.',\n",
       " 'And tonight I ask for yours.',\n",
       " 'Together, let us protect our country, support the men and women who defend us, and lead this world toward freedom.',\n",
       " '(Applause.)',\n",
       " 'Here at home, America also has a great opportunity: We will build the prosperity of our country by strengthening our economic leadership in the world.',\n",
       " 'Our economy is healthy and vigorous, and growing faster than other major industrialized nations.',\n",
       " 'In the last two-and-a-half years, America has created 4.6 million new jobs -- more than Japan and the European Union combined.',\n",
       " '(Applause.)',\n",
       " 'Even in the face of higher energy prices and natural disasters, the American people have turned in an economic performance that is the envy of the world.',\n",
       " 'The American economy is preeminent, but we cannot afford to be complacent.',\n",
       " \"In a dynamic world economy, we are seeing new competitors, like China and India, and this creates uncertainty, which makes it easier to feed people's fears.\",\n",
       " \"So we're seeing some old temptations return.\",\n",
       " 'Protectionists want to escape competition, pretending that we can keep our high standard of living while walling off our economy.',\n",
       " 'Others say that the government needs to take a larger role in directing the economy, centralizing more power in Washington and increasing taxes.',\n",
       " 'We hear claims that immigrants are somehow bad for the economy -- even though this economy could not function without them.',\n",
       " '(Applause.)',\n",
       " 'All these are forms of economic retreat, and they lead in the same direction -- toward a stagnant and second-rate economy.',\n",
       " 'Tonight I will set out a better path: an agenda for a nation that competes with confidence; an agenda that will raise standards of living and generate new jobs.',\n",
       " 'Americans should not fear our economic future, because we intend to shape it.',\n",
       " 'Keeping America competitive begins with keeping our economy growing.',\n",
       " 'And our economy grows when Americans have more of their own money to spend, save, and invest.',\n",
       " 'In the last five years, the tax relief you passed has left $880 billion in the hands of American workers, investors, small businesses, and families -- and they have used it to help produce more than four years of uninterrupted economic growth.',\n",
       " '(Applause.)',\n",
       " 'Yet the tax relief is set to expire in the next few years.',\n",
       " 'If we do nothing, American families will face a massive tax increase they do not expect and will not welcome.',\n",
       " 'Because America needs more than a temporary expansion, we need more than temporary tax relief.',\n",
       " 'I urge the Congress to act responsibly, and make the tax cuts permanent.',\n",
       " '(Applause.)',\n",
       " 'Keeping America competitive requires us to be good stewards of tax dollars.',\n",
       " \"Every year of my presidency, we've reduced the growth of non-security discretionary spending, and last year you passed bills that cut this spending.\",\n",
       " 'This year my budget will cut it again, and reduce or eliminate more than 140 programs that are performing poorly or not fulfilling essential priorities.',\n",
       " 'By passing these reforms, we will save the American taxpayer another $14 billion next year, and stay on track to cut the deficit in half by 2009.',\n",
       " '(Applause.)',\n",
       " 'I am pleased that members of Congress are working on earmark reform, because the federal budget has too many special interest projects.',\n",
       " '(Applause.)',\n",
       " 'And we can tackle this problem together, if you pass the line-item veto.',\n",
       " '(Applause.)',\n",
       " 'We must also confront the larger challenge of mandatory spending, or entitlements.',\n",
       " \"This year, the first of about 78 million baby boomers turn 60, including two of my Dad's favorite people -- me and President Clinton.\",\n",
       " '(Laughter.)',\n",
       " 'This milestone is more than a personal crisis -- (laughter) -- it is a national challenge.',\n",
       " 'The retirement of the baby boom generation will put unprecedented strains on the federal government.',\n",
       " 'By 2030, spending for Social Security, Medicare and Medicaid alone will be almost 60 percent of the entire federal budget.',\n",
       " 'And that will present future Congresses with impossible choices -- staggering tax increases, immense deficits, or deep cuts in every category of spending.',\n",
       " 'Congress did not act last year on my proposal to save Social Security -- (applause) -- yet the rising cost of entitlements is a problem that is not going away.',\n",
       " '(Applause.)',\n",
       " 'And every year we fail to act, the situation gets worse.',\n",
       " 'So tonight, I ask you to join me in creating a commission to examine the full impact of baby boom retirements on Social Security, Medicare, and Medicaid.',\n",
       " 'This commission should include members of Congress of both parties, and offer bipartisan solutions.',\n",
       " 'We need to put aside partisan politics and work together and get this problem solved.',\n",
       " '(Applause.)',\n",
       " 'Keeping America competitive requires us to open more markets for all that Americans make and grow.',\n",
       " 'One out of every five factory jobs in America is related to global trade, and we want people everywhere to buy American.',\n",
       " 'With open markets and a level playing field, no one can out-produce or out-compete the American worker.',\n",
       " '(Applause.)',\n",
       " 'Keeping America competitive requires an immigration system that upholds our laws, reflects our values, and serves the interests of our economy.',\n",
       " 'Our nation needs orderly and secure borders.',\n",
       " '(Applause.)',\n",
       " 'To meet this goal, we must have stronger immigration enforcement and border protection.',\n",
       " '(Applause.)',\n",
       " 'And we must have a rational, humane guest worker program that rejects amnesty, allows temporary jobs for people who seek them legally, and reduces smuggling and crime at the border.',\n",
       " '(Applause.)',\n",
       " 'Keeping America competitive requires affordable health care.',\n",
       " '(Applause.)',\n",
       " 'Our government has a responsibility to provide health care for the poor and the elderly, and we are meeting that responsibility.',\n",
       " '(Applause.)',\n",
       " 'For all Americans -- for all Americans, we must confront the rising cost of care, strengthen the doctor-patient relationship, and help people afford the insurance coverage they need.',\n",
       " '(Applause.)',\n",
       " 'We will make wider use of electronic records and other health information technology, to help control costs and reduce dangerous medical errors.',\n",
       " 'We will strengthen health savings accounts -- making sure individuals and small business employees can buy insurance with the same advantages that people working for big businesses now get.',\n",
       " '(Applause.)',\n",
       " 'We will do more to make this coverage portable, so workers can switch jobs without having to worry about losing their health insurance.',\n",
       " '(Applause.)',\n",
       " 'And because lawsuits are driving many good doctors out of practice -- leaving women in nearly 1,500 American counties without a single OB/GYN -- I ask the Congress to pass medical liability reform this year.',\n",
       " '(Applause.)',\n",
       " 'Keeping America competitive requires affordable energy.',\n",
       " 'And here we have a serious problem: America is addicted to oil, which is often imported from unstable parts of the world.',\n",
       " 'The best way to break this addiction is through technology.',\n",
       " 'Since 2001, we have spent nearly $10 billion to develop cleaner, cheaper, and more reliable alternative energy sources -- and we are on the threshold of incredible advances.',\n",
       " 'So tonight, I announce the Advanced Energy Initiative -- a 22-percent increase in clean-energy research -- at the Department of Energy, to push for breakthroughs in two vital areas.',\n",
       " 'To change how we power our homes and offices, we will invest more in zero-emission coal-fired plants, revolutionary solar and wind technologies, and clean, safe nuclear energy.',\n",
       " '(Applause.)',\n",
       " 'We must also change how we power our automobiles.',\n",
       " 'We will increase our research in better batteries for hybrid and electric cars, and in pollution-free cars that run on hydrogen.',\n",
       " \"We'll also fund additional research in cutting-edge methods of producing ethanol, not just from corn, but from wood chips and stalks, or switch grass.\",\n",
       " 'Our goal is to make this new kind of ethanol practical and competitive within six years.',\n",
       " '(Applause.)',\n",
       " 'Breakthroughs on this and other new technologies will help us reach another great goal: to replace more than 75 percent of our oil imports from the Middle East by 2025.',\n",
       " '(Applause.)',\n",
       " 'By applying the talent and technology of America, this country can dramatically improve our environment, move beyond a petroleum-based economy, and make our dependence on Middle Eastern oil a thing of the past.',\n",
       " '(Applause.)',\n",
       " 'And to keep America competitive, one commitment is necessary above all: We must continue to lead the world in human talent and creativity.',\n",
       " \"Our greatest advantage in the world has always been our educated, hardworking, ambitious people -- and we're going to keep that edge.\",\n",
       " \"Tonight I announce an American Competitiveness Initiative, to encourage innovation throughout our economy, and to give our nation's children a firm grounding in math and science.\",\n",
       " '(Applause.)',\n",
       " 'First, I propose to double the federal commitment to the most critical basic research programs in the physical sciences over the next 10 years.',\n",
       " \"This funding will support the work of America's most creative minds as they explore promising areas such as nanotechnology, supercomputing, and alternative energy sources.\",\n",
       " 'Second, I propose to make permanent the research and development tax credit -- (applause) -- to encourage bolder private-sector initiatives in technology.',\n",
       " 'With more research in both the public and private sectors, we will improve our quality of life -- and ensure that America will lead the world in opportunity and innovation for decades to come.',\n",
       " '(Applause.)',\n",
       " 'Third, we need to encourage children to take more math and science, and to make sure those courses are rigorous enough to compete with other nations.',\n",
       " \"We've made a good start in the early grades with the No Child Left Behind Act, which is raising standards and lifting test scores across our country.\",\n",
       " 'Tonight I propose to train 70,000 high school teachers to lead advanced-placement courses in math and science, bring 30,000 math and science professionals to teach in classrooms, and give early help to students who struggle with math, so they have a better chance at good, high-wage jobs.',\n",
       " \"If we ensure that America's children succeed in life, they will ensure that America succeeds in the world.\",\n",
       " '(Applause.)',\n",
       " 'Preparing our nation to compete in the world is a goal that all of us can share.',\n",
       " 'I urge you to support the American Competitiveness Initiative, and together we will show the world what the American people can achieve.',\n",
       " 'America is a great force for freedom and prosperity.',\n",
       " 'Yet our greatness is not measured in power or luxuries, but by who we are and how we treat one another.',\n",
       " 'So we strive to be a compassionate, decent, hopeful society.',\n",
       " 'In recent years, America has become a more hopeful nation.',\n",
       " 'Violent crime rates have fallen to their lowest levels since the 1970s.',\n",
       " 'Welfare cases have dropped by more than half over the past decade.',\n",
       " 'Drug use among youth is down 19 percent since 2001.',\n",
       " 'There are fewer abortions in America than at any point in the last three decades, and the number of children born to teenage mothers has been falling for a dozen years in a row.',\n",
       " '(Applause.)',\n",
       " 'These gains are evidence of a quiet transformation -- a revolution of conscience, in which a rising generation is finding that a life of personal responsibility is a life of fulfillment.',\n",
       " 'Government has played a role.',\n",
       " 'Wise policies, such as welfare reform and drug education and support for abstinence and adoption have made a difference in the character of our country.',\n",
       " 'And everyone here tonight, Democrat and Republican, has a right to be proud of this record.',\n",
       " '(Applause.)',\n",
       " 'Yet many Americans, especially parents, still have deep concerns about the direction of our culture, and the health of our most basic institutions.',\n",
       " \"They're concerned about unethical conduct by public officials, and discouraged by activist courts that try to redefine marriage.\",\n",
       " 'They worry about children in our society who need direction and love, and about fellow citizens still displaced by natural disaster, and about suffering caused by treatable diseases.',\n",
       " 'As we look at these challenges, we must never give in to the belief that America is in decline, or that our culture is doomed to unravel.',\n",
       " 'The American people know better than that.',\n",
       " 'We have proven the pessimists wrong before -- and we will do it again.',\n",
       " '(Applause.)',\n",
       " 'A hopeful society depends on courts that deliver equal justice under the law.',\n",
       " 'The Supreme Court now has two superb new members -- new members on its bench: Chief Justice John Roberts and Justice Sam Alito.',\n",
       " '(Applause.)',\n",
       " 'I thank the Senate for confirming both of them.',\n",
       " 'I will continue to nominate men and women who understand that judges must be servants of the law, and not legislate from the bench.',\n",
       " '(Applause.)',\n",
       " 'Today marks the official retirement of a very special American.',\n",
       " \"For 24 years of faithful service to our nation, the United States is grateful to Justice Sandra Day O'Connor.\",\n",
       " '(Applause.)',\n",
       " 'A hopeful society has institutions of science and medicine that do not cut ethical corners, and that recognize the matchless value of every life.',\n",
       " 'Tonight I ask you to pass legislation to prohibit the most egregious abuses of medical research: human cloning in all its forms, creating or implanting embryos for experiments, creating human-animal hybrids, and buying, selling, or patenting human embryos.',\n",
       " 'Human life is a gift from our Creator -- and that gift should never be discarded, devalued or put up for sale.',\n",
       " '(Applause.)',\n",
       " 'A hopeful society expects elected officials to uphold the public trust.',\n",
       " '(Applause.)',\n",
       " 'Honorable people in both parties are working on reforms to strengthen the ethical standards of Washington -- I support your efforts.',\n",
       " 'Each of us has made a pledge to be worthy of public responsibility -- and that is a pledge we must never forget, never dismiss, and never betray.',\n",
       " '(Applause.)',\n",
       " 'As we renew the promise of our institutions, let us also show the character of America in our compassion and care for one another.',\n",
       " 'A hopeful society gives special attention to children who lack direction and love.',\n",
       " \"Through the Helping America's Youth Initiative, we are encouraging caring adults to get involved in the life of a child -- and this good work is being led by our First Lady, Laura Bush.\",\n",
       " '(Applause.)',\n",
       " \"This year we will add resources to encourage young people to stay in school, so more of America's youth can raise their sights and achieve their dreams.\",\n",
       " \"A hopeful society comes to the aid of fellow citizens in times of suffering and emergency -- and stays at it until they're back on their feet.\",\n",
       " 'So far the federal government has committed $85 billion to the people of the Gulf Coast and New Orleans.',\n",
       " \"We're removing debris and repairing highways and rebuilding stronger levees.\",\n",
       " \"We're providing business loans and housing assistance.\",\n",
       " 'Yet as we meet these immediate needs, we must also address deeper challenges that existed before the storm arrived.',\n",
       " 'In New Orleans and in other places, many of our fellow citizens have felt excluded from the promise of our country.',\n",
       " 'The answer is not only temporary relief, but schools that teach every child, and job skills that bring upward mobility, and more opportunities to own a home and start a business.',\n",
       " 'As we recover from a disaster, let us also work for the day when all Americans are protected by justice, equal in hope, and rich in opportunity.',\n",
       " '(Applause.)',\n",
       " 'A hopeful society acts boldly to fight diseases like HIV/AIDS, which can be prevented, and treated, and defeated.',\n",
       " 'More than a million Americans live with HIV, and half of all AIDS cases occur among African Americans.',\n",
       " 'I ask Congress to reform and reauthorize the Ryan White Act, and provide new funding to states, so we end the waiting lists for AIDS medicines in America.',\n",
       " '(Applause.)',\n",
       " 'We will also lead a nationwide effort, working closely with African American churches and faith-based groups, to deliver rapid HIV tests to millions, end the stigma of AIDS, and come closer to the day when there are no new infections in America.',\n",
       " '(Applause.)',\n",
       " \"Fellow citizens, we've been called to leadership in a period of consequence.\",\n",
       " \"We've entered a great ideological conflict we did nothing to invite.\",\n",
       " 'We see great changes in science and commerce that will influence all our lives.',\n",
       " 'Sometimes it can seem that history is turning in a wide arc, toward an unknown shore.',\n",
       " 'Yet the destination of history is determined by human action, and every great movement of history comes to a point of choosing.',\n",
       " 'Lincoln could have accepted peace at the cost of disunity and continued slavery.',\n",
       " 'Martin Luther King could have stopped at Birmingham or at Selma, and achieved only half a victory over segregation.',\n",
       " 'The United States could have accepted the permanent division of Europe, and been complicit in the oppression of others.',\n",
       " 'Today, having come far in our own historical journey, we must decide: Will we turn back, or finish well?',\n",
       " 'Before history is written down in books, it is written in courage.',\n",
       " 'Like Americans before us, we will show that courage and we will finish well.',\n",
       " \"We will lead freedom's advance.\",\n",
       " 'We will compete and excel in the global economy.',\n",
       " 'We will renew the defining moral commitments of this land.',\n",
       " 'And so we move forward -- optimistic about our country, faithful to its cause, and confident of the victories to come.',\n",
       " 'May God bless America.',\n",
       " '(Applause.)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized = custom_sent_tokenizer.tokenize(sample_text);tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[:5]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            print(tagged)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PRESIDENT', 'NNP'), ('GEORGE', 'NNP'), ('W.', 'NNP'), ('BUSH', 'NNP'), (\"'S\", 'POS'), ('ADDRESS', 'NNP'), ('BEFORE', 'IN'), ('A', 'NNP'), ('JOINT', 'NNP'), ('SESSION', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('CONGRESS', 'NNP'), ('ON', 'NNP'), ('THE', 'NNP'), ('STATE', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('UNION', 'NNP'), ('January', 'NNP'), ('31', 'CD'), (',', ','), ('2006', 'CD'), ('THE', 'NNP'), ('PRESIDENT', 'NNP'), (':', ':'), ('Thank', 'NNP'), ('you', 'PRP'), ('all', 'DT'), ('.', '.')]\n",
      "[('Mr.', 'NNP'), ('Speaker', 'NNP'), (',', ','), ('Vice', 'NNP'), ('President', 'NNP'), ('Cheney', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('Congress', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('Supreme', 'NNP'), ('Court', 'NNP'), ('and', 'CC'), ('diplomatic', 'JJ'), ('corps', 'NN'), (',', ','), ('distinguished', 'JJ'), ('guests', 'NNS'), (',', ','), ('and', 'CC'), ('fellow', 'JJ'), ('citizens', 'NNS'), (':', ':'), ('Today', 'VB'), ('our', 'PRP$'), ('nation', 'NN'), ('lost', 'VBD'), ('a', 'DT'), ('beloved', 'VBN'), (',', ','), ('graceful', 'JJ'), (',', ','), ('courageous', 'JJ'), ('woman', 'NN'), ('who', 'WP'), ('called', 'VBD'), ('America', 'NNP'), ('to', 'TO'), ('its', 'PRP$'), ('founding', 'NN'), ('ideals', 'NNS'), ('and', 'CC'), ('carried', 'VBD'), ('on', 'IN'), ('a', 'DT'), ('noble', 'JJ'), ('dream', 'NN'), ('.', '.')]\n",
      "[('Tonight', 'NN'), ('we', 'PRP'), ('are', 'VBP'), ('comforted', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('hope', 'NN'), ('of', 'IN'), ('a', 'DT'), ('glad', 'JJ'), ('reunion', 'NN'), ('with', 'IN'), ('the', 'DT'), ('husband', 'NN'), ('who', 'WP'), ('was', 'VBD'), ('taken', 'VBN'), ('so', 'RB'), ('long', 'RB'), ('ago', 'RB'), (',', ','), ('and', 'CC'), ('we', 'PRP'), ('are', 'VBP'), ('grateful', 'JJ'), ('for', 'IN'), ('the', 'DT'), ('good', 'JJ'), ('life', 'NN'), ('of', 'IN'), ('Coretta', 'NNP'), ('Scott', 'NNP'), ('King', 'NNP'), ('.', '.')]\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "[('President', 'NNP'), ('George', 'NNP'), ('W.', 'NNP'), ('Bush', 'NNP'), ('reacts', 'VBZ'), ('to', 'TO'), ('applause', 'VB'), ('during', 'IN'), ('his', 'PRP$'), ('State', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('Union', 'NNP'), ('Address', 'NNP'), ('at', 'IN'), ('the', 'DT'), ('Capitol', 'NNP'), (',', ','), ('Tuesday', 'NNP'), (',', ','), ('Jan', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Chunking with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The main goals of chunking is to group into what are known as \"noun phrases\" , 명사구나 명사절 등등\n",
    "##### to group nouns with the words that are in relation to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (Chunk PRESIDENT/NNP GEORGE/NNP W./NNP BUSH/NNP)\n",
      "  'S/POS\n",
      "  (Chunk ADDRESS/NNP)\n",
      "  BEFORE/IN\n",
      "  (Chunk A/NNP JOINT/NNP SESSION/NNP)\n",
      "  OF/IN\n",
      "  (Chunk THE/NNP CONGRESS/NNP ON/NNP THE/NNP STATE/NNP)\n",
      "  OF/IN\n",
      "  (Chunk THE/NNP UNION/NNP January/NNP)\n",
      "  31/CD\n",
      "  ,/,\n",
      "  2006/CD\n",
      "  (Chunk THE/NNP PRESIDENT/NNP)\n",
      "  :/:\n",
      "  (Chunk Thank/NNP)\n",
      "  you/PRP\n",
      "  all/DT\n",
      "  ./.)\n",
      "(Chunk PRESIDENT/NNP GEORGE/NNP W./NNP BUSH/NNP)\n",
      "(Chunk ADDRESS/NNP)\n",
      "(Chunk A/NNP JOINT/NNP SESSION/NNP)\n",
      "(Chunk THE/NNP CONGRESS/NNP ON/NNP THE/NNP STATE/NNP)\n",
      "(Chunk THE/NNP UNION/NNP January/NNP)\n",
      "(Chunk THE/NNP PRESIDENT/NNP)\n",
      "(Chunk Thank/NNP)\n"
     ]
    }
   ],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            \n",
    "            print(chunked)\n",
    "            for subtree in chunked.subtrees(filter=lambda t: t.label() == 'Chunk'):\n",
    "                print(subtree)\n",
    "            \n",
    "            chunked.draw()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 6. Chinking with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nchuniking을 해도 아직 원하지 않는 words들이 남아있을 수 있다.\\nchinking은 chunking과 비슷하다. \\nchink = the chunk that you remove from your chunk\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "chuniking을 해도 아직 원하지 않는 words들이 남아있을 수 있다.\n",
    "chinking은 chunking과 비슷하다. \n",
    "chink = the chunk that you remove from your chunk\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[5:]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "\n",
    "            chunkGram = r\"\"\"Chunk: {<.*>+}\n",
    "                                    }<VB.?|IN|DT|TO>+{\"\"\"\n",
    "\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "\n",
    "            chunked.draw()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Named Entity Recognition with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n두 가지 주요한 option이 있다.\\n1) recognize all named entitis\\n2) recognize named entities as their respective type(people, places, locations, etc.)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "두 가지 주요한 option이 있다.\n",
    "1) recognize all named entities\n",
    "2) recognize named entities as their respective type(people, places, locations, etc.)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[5:]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            namedEnt = nltk.ne_chunk(tagged, binary=True)\n",
    "            namedEnt.draw()\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\"white house\"를 예를 들어서 \n",
    "binary=True\n",
    "    same named entitty로 묶어서\n",
    "binary=False\n",
    "    splitting up terms 각각 다르게\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Lemmatizing with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstemming과 비슷한 작업.\\nstemming은 어간을 추출하는데 종종 존재하지 않는 단어를 create해낸다.\\n반면에, lemmatizing은 actual words만 생성한다.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "stemming과 비슷한 작업.\n",
    "stemming은 어간을 추출하는데 종종 존재하지 않는 단어를 create해낸다.\n",
    "반면에, lemmatizing은 actual words만 생성한다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "cactus\n",
      "goose\n",
      "rock\n",
      "python\n",
      "good\n",
      "best\n",
      "run\n",
      "swim\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize(\"cats\"))\n",
    "print(lemmatizer.lemmatize(\"cacti\"))\n",
    "print(lemmatizer.lemmatize(\"geese\"))\n",
    "print(lemmatizer.lemmatize(\"rocks\"))\n",
    "print(lemmatizer.lemmatize(\"python\"))\n",
    "print(lemmatizer.lemmatize(\"better\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"best\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"run\"))\n",
    "print(lemmatizer.lemmatize(\"swimming\",'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nparameter로 pos를 가질 수 있는데 default는 noun이다.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "parameter로 pos를 가질 수 있는데 default는 noun이다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. The Corpora With NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import nltk, os, sys\n",
    "print(nltk.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = str(r'C:\\nltk_data')\n",
    "path = os.path.join(sys.prefix, str('nltk_data'))\n",
    "path = os.path.join(sys.prefix, str('lib'), str('nltk_data'))\n",
    "path = os.path.join(os.environ.get(str('APPDATA'), str('C:\\\\')), str('nltk_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\yonghoon\\\\AppData\\\\Roaming\\\\nltk_data'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, PunktSentenceTokenizer\n",
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = gutenberg.raw(\"bible-kjv.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tok = sent_tokenize(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The King James Bible]\n",
      "\n",
      "The Old Testament of the King James Bible\n",
      "\n",
      "The First Book of Moses:  Called Genesis\n",
      "\n",
      "\n",
      "1:1 In the beginning God created the heaven and the earth.\n",
      "1:2 And the earth was without form, and void; and darkness was upon\n",
      "the face of the deep.\n",
      "And the Spirit of God moved upon the face of the\n",
      "waters.\n",
      "1:3 And God said, Let there be light: and there was light.\n",
      "1:4 And God saw the light, that it was good: and God divided the light\n",
      "from the darkness.\n"
     ]
    }
   ],
   "source": [
    "for x in range(5):\n",
    "    print(tok[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Wordnet With NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwordnet is a lexical database for the English language, created by Princeton\\n단어의 synonyms, antonyms, 단어 간 similarity 등을 계산할 수 있다.\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "wordnet is a lexical database for the English language, created by Princeton\n",
    "단어의 synonyms, antonyms, 단어 간 similarity 등을 계산할 수 있다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "syns = wordnet.synsets(\"program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('plan.n.01')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan.n.01\n"
     ]
    }
   ],
   "source": [
    "print(syns[0].name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('plan.n.01.plan'),\n",
       " Lemma('plan.n.01.program'),\n",
       " Lemma('plan.n.01.programme')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syns[0].lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan\n"
     ]
    }
   ],
   "source": [
    "print(syns[0].lemmas()[0].name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a series of steps to be carried out or goals to be accomplished\n"
     ]
    }
   ],
   "source": [
    "print(syns[0].definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['they drew up a six-step plan', 'they discussed plans for a new bond issue']\n"
     ]
    }
   ],
   "source": [
    "print(syns[0].examples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimable', 'sound', 'safe', 'upright', 'full', 'goodness', 'skilful', 'well', 'near', 'in_force', 'honest', 'serious', 'unspoiled', 'commodity', 'effective', 'skillful', 'just', 'right', 'in_effect', 'practiced', 'good', 'unspoilt', 'respectable', 'adept', 'proficient', 'trade_good', 'expert', 'soundly', 'honorable', 'beneficial', 'dependable', 'dear', 'secure', 'undecomposed', 'salutary', 'thoroughly', 'ripe'}\n",
      "{'ill', 'badness', 'bad', 'evilness', 'evil'}\n"
     ]
    }
   ],
   "source": [
    "synonyms = []\n",
    "antonyms = []\n",
    "for syn in wordnet.synsets(\"good\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "print(set(synonyms))\n",
    "print(set(antonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "w1 = wordnet.synset('ship.n.01')\n",
    "w2 = wordnet.synset('boat.n.01')\n",
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6956521739130435\n"
     ]
    }
   ],
   "source": [
    "w1 = wordnet.synset('ship.n.01')\n",
    "w2 = wordnet.synset('car.n.01')\n",
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32\n"
     ]
    }
   ],
   "source": [
    "w1 = wordnet.synset('ship.n.01')\n",
    "w2 = wordnet.synset('cat.n.01')\n",
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Text Classfication with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntext classfication하기 위해서는 data에 labelling이 되어 있어야한다.\\npos/neg class\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "text classfication하기 위해서는 data에 labelling이 되어 있어야한다.\n",
    "pos/neg class\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(documents)\n",
    "# label이 고루 섞이게 하기 위해서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['it', \"'\", 's', 'a', 'fact', 'that', 'a', 'good', 'thriller', 'or', 'action', 'movie', 'doesn', \"'\", 't', 'need', 'violence', 'to', 'be', 'good', 'or', 'worth', 'watching', '.', 'all', 'it', 'takes', 'is', 'potential', 'violence', 'to', 'make', 'the', 'audience', 'bite', 'their', 'nails', '.', 'and', 'what', 'kind', 'of', 'violence', 'could', 'be', 'more', 'efficient', 'than', 'a', 'global', 'thermo', '-', 'nuclear', 'war', '?', 'and', 'potential', 'violence', 'is', 'the', 'premiss', 'wargames', 'is', 'built', 'upon', '.', 'a', 'computer', 'whiz', '-', 'kid', ',', 'david', ',', 'is', 'usually', 'contended', 'with', 'hacking', 'into', 'the', 'school', 'computer', 'to', 'change', 'his', 'grades', '.', 'but', 'after', 'having', 'read', 'an', 'advertisment', 'for', 'an', 'upcoming', 'computer', 'game', ',', 'he', 'wants', 'to', 'be', 'the', 'first', 'to', 'play', 'it', '.', 'instead', 'of', 'getting', 'into', 'the', 'computer', 'at', 'protovision', 'software', 'he', 'accidentally', 'comes', 'to', 'the', 'frontgate', 'of', 'norad', '.', 'with', 'the', 'help', 'of', 'jennifer', ',', 'a', 'girl', 'in', 'his', 'biology', 'class', ',', 'he', 'starts', 'to', 'play', 'a', 'nice', 'game', 'of', 'nuclear', 'war', 'with', 'wopr', ',', 'war', 'operation', 'plan', 'response', '(', 'a', 'top', '-', 'notch', 'computer', 'at', 'the', 'time', ',', 'but', 'now', 'hardly', 'faster', 'than', 'my', 'own', 'computer', ')', 'i', 'remember', 'being', '12', 'and', 'watching', 'this', 'at', 'the', 'cinema', '.', 'it', 'was', 'very', 'efficent', 'at', 'giving', 'you', 'a', 'scare', 'in', 'those', 'days', 'and', 'that', 'hasn', \"'\", 't', 'changed', '.', 'of', 'course', ',', 'a', 'nuclear', 'war', 'seemed', 'to', 'be', 'much', 'more', 'of', 'something', 'that', 'could', 'actually', 'happen', 'back', 'in', '1983', '.', 'i', 'wouldn', \"'\", 't', 'be', 'surprised', 'if', 'this', 'gave', 'people', 'nightmares', '.', 'i', 'hope', 'it', 'still', 'does', 'since', 'you', 'still', 'hear', 'about', 'school', 'kids', 'hacking', 'into', 'the', 'computers', 'at', 'pentagon', '.', 'broderick', 'and', 'sheedy', 'are', 'just', 'fine', 'as', 'the', 'young', 'teenagers', '(', 'although', 'her', 'interest', 'in', 'david', 'remains', 'a', 'mystery', ')', '.', 'but', 'the', 'rest', 'of', 'the', 'actors', 'are', ',', 'by', 'no', 'fault', 'of', 'their', 'own', ',', 'restricted', 'by', 'the', 'script', 'to', 'play', 'one', '-', 'dimensional', 'grownups', '.', 'david', \"'\", 's', 'parents', 'are', 'the', 'same', 'kind', 'of', 'parents', 'that', 'populate', 'all', 'these', 'college', 'comedies', 'from', 'the', '1980s', ',', 'movies', 'like', 'secret', 'admirer', ',', 'porky', \"'\", 's', 'or', 'zapped', 'and', 'the', 'norad', 'general', 'beringer', 'is', 'straight', 'out', 'of', 'dr', '.', 'strangelove', '.', 'if', 'for', 'no', 'other', 'reason', ',', 'you', 'should', 'see', 'this', 'movie', 'to', 'enjoy', 'how', 'far', 'the', 'computer', 'technology', 'has', 'gone', 'since', 'those', 'days', '.', 'david', 'uses', 'the', 'same', 'telephone', 'for', 'calling', 'friends', 'as', 'calling', 'other', 'computers', '.', 'the', 'modem', 'is', 'some', 'kind', 'of', 'device', 'that', 'he', 'puts', 'the', 'headset', 'on', '.', 'far', 'from', 'any', '56k', 'modem', 'my', 'guess', 'is', 'that', 'it', \"'\", 's', 'some', 'kind', 'of', '2400', 'bps', 'modem', ',', 'the', 'kind', 'of', 'technology', 'you', 'now', 'find', 'at', 'your', 'local', 'technical', 'museum', '.', 'the', 'big', 'computer', 'at', 'norad', 'has', 'a', 'lot', 'of', 'flashing', 'lights', '(', 'just', 'like', 'those', 'you', 'see', 'on', 'star', 'trek', 'or', 'any', 'old', 'sf', '-', 'movie', ')', 'but', 'it', \"'\", 's', 'hardly', 'impressing', 'compared', 'with', 'what', 'you', 'can', 'get', 'today', '.', 'what', 'are', 'the', 'lessons', 'we', 'can', 'learn', 'from', 'wargames', '?', '1', '.', 'make', 'sure', 'there', 'are', 'no', 'secret', 'backdoors', 'into', 'military', 'computers', '.', '2', '.', 'thank', 'you', ',', 'whoever', 'it', 'was', ',', 'for', 'giving', 'us', 'a', 'graphical', 'user', 'interface', 'when', 'we', 'use', 'our', 'computers', '!'], 'pos')\n"
     ]
    }
   ],
   "source": [
    "print(documents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "# movie_reviews의 corpus에서 모든 단어를 추출해 소문자로 변환후 all_words list에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 77717), ('the', 76529), ('.', 65876), ('a', 38106), ('and', 35576), ('of', 34123), ('to', 31937), (\"'\", 30585), ('is', 25195), ('in', 21822), ('s', 18513), ('\"', 17612), ('it', 16107), ('that', 15924), ('-', 15595)]\n",
      "253\n"
     ]
    }
   ],
   "source": [
    "all_words = nltk.FreqDist(all_words)\n",
    "print(all_words.most_common(15))\n",
    "print(all_words[\"stupid\"])\n",
    "\n",
    "# 단어의 출현빈도를 확인\n",
    "# FreqDist, 단어간 출현빈도를 적은 key-value dictionary이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words, freq = zip(*all_words.most_common(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(',', 'the', '.', 'a', 'and', 'of', 'to', \"'\", 'is', 'in', 's', '\"', 'it', 'that', '-')\n",
      "(77717, 76529, 65876, 38106, 35576, 34123, 31937, 30585, 25195, 21822, 18513, 17612, 16107, 15924, 15595)\n"
     ]
    }
   ],
   "source": [
    "print(words)\n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1e87a473dd8>,\n",
       "  <matplotlib.axis.XTick at 0x1e87a45c908>,\n",
       "  <matplotlib.axis.XTick at 0x1e87a46dda0>,\n",
       "  <matplotlib.axis.XTick at 0x1e87a4889e8>,\n",
       "  <matplotlib.axis.XTick at 0x1e87a48f0f0>,\n",
       "  <matplotlib.axis.XTick at 0x1e87a48f908>,\n",
       "  <matplotlib.axis.XTick at 0x1e87a4900b8>,\n",
       "  <matplotlib.axis.XTick at 0x1e87a4907f0>,\n",
       "  <matplotlib.axis.XTick at 0x1e87a490f28>,\n",
       "  <matplotlib.axis.XTick at 0x1e87a4916a0>,\n",
       "  <matplotlib.axis.XTick at 0x1e87a491d68>,\n",
       "  <matplotlib.axis.XTick at 0x1e87a4924a8>,\n",
       "  <matplotlib.axis.XTick at 0x1e87a492ba8>,\n",
       "  <matplotlib.axis.XTick at 0x1e87a493358>,\n",
       "  <matplotlib.axis.XTick at 0x1e87a493a58>],\n",
       " <a list of 15 Text xticklabel objects>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAFQCAYAAACLa8j2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKBwAgBEUDgDACAoHAGDE/wM9+a+x3A3LcwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e87a46b390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot freqdist desc orders\n",
    "plt.bar(range(len(words)), freq)\n",
    "plt.xticks(range(len(words)),words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Converting words to Features with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n이전 튜토리얼의 build off(발전시키다)\\npos/neg label대로 feature list를 생성하고자 함\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "이전 튜토리얼의 build off(발전시키다)\n",
    "pos/neg label대로 feature list를 생성하고자 함\n",
    "feature list는 빈출 단어의 출현 유무를 알려주는 dictionary\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plot',\n",
       " ':',\n",
       " 'two',\n",
       " 'teen',\n",
       " 'couples',\n",
       " 'go',\n",
       " 'to',\n",
       " 'a',\n",
       " 'church',\n",
       " 'party',\n",
       " ',',\n",
       " 'drink',\n",
       " 'and',\n",
       " 'then',\n",
       " 'drive',\n",
       " '.',\n",
       " 'they',\n",
       " 'get',\n",
       " 'into',\n",
       " 'an',\n",
       " 'accident',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'guys',\n",
       " 'dies',\n",
       " 'but',\n",
       " 'his',\n",
       " 'girlfriend',\n",
       " 'continues',\n",
       " 'see',\n",
       " 'him',\n",
       " 'in',\n",
       " 'her',\n",
       " 'life',\n",
       " 'has',\n",
       " 'nightmares',\n",
       " 'what',\n",
       " \"'\",\n",
       " 's',\n",
       " 'deal',\n",
       " '?',\n",
       " 'watch',\n",
       " 'movie',\n",
       " '\"',\n",
       " 'sorta',\n",
       " 'find',\n",
       " 'out',\n",
       " 'critique',\n",
       " 'mind',\n",
       " '-',\n",
       " 'fuck',\n",
       " 'for',\n",
       " 'generation',\n",
       " 'that',\n",
       " 'touches',\n",
       " 'on',\n",
       " 'very',\n",
       " 'cool',\n",
       " 'idea',\n",
       " 'presents',\n",
       " 'it',\n",
       " 'bad',\n",
       " 'package',\n",
       " 'which',\n",
       " 'is',\n",
       " 'makes',\n",
       " 'this',\n",
       " 'review',\n",
       " 'even',\n",
       " 'harder',\n",
       " 'write',\n",
       " 'since',\n",
       " 'i',\n",
       " 'generally',\n",
       " 'applaud',\n",
       " 'films',\n",
       " 'attempt',\n",
       " 'break',\n",
       " 'mold',\n",
       " 'mess',\n",
       " 'with',\n",
       " 'your',\n",
       " 'head',\n",
       " 'such',\n",
       " '(',\n",
       " 'lost',\n",
       " 'highway',\n",
       " '&',\n",
       " 'memento',\n",
       " ')',\n",
       " 'there',\n",
       " 'are',\n",
       " 'good',\n",
       " 'ways',\n",
       " 'making',\n",
       " 'all',\n",
       " 'types',\n",
       " 'these',\n",
       " 'folks',\n",
       " 'just',\n",
       " 'didn',\n",
       " 't',\n",
       " 'snag',\n",
       " 'correctly',\n",
       " 'seem',\n",
       " 'have',\n",
       " 'taken',\n",
       " 'pretty',\n",
       " 'neat',\n",
       " 'concept',\n",
       " 'executed',\n",
       " 'terribly',\n",
       " 'so',\n",
       " 'problems',\n",
       " 'well',\n",
       " 'its',\n",
       " 'main',\n",
       " 'problem',\n",
       " 'simply',\n",
       " 'too',\n",
       " 'jumbled',\n",
       " 'starts',\n",
       " 'off',\n",
       " 'normal',\n",
       " 'downshifts',\n",
       " 'fantasy',\n",
       " 'world',\n",
       " 'you',\n",
       " 'as',\n",
       " 'audience',\n",
       " 'member',\n",
       " 'no',\n",
       " 'going',\n",
       " 'dreams',\n",
       " 'characters',\n",
       " 'coming',\n",
       " 'back',\n",
       " 'from',\n",
       " 'dead',\n",
       " 'others',\n",
       " 'who',\n",
       " 'look',\n",
       " 'like',\n",
       " 'strange',\n",
       " 'apparitions',\n",
       " 'disappearances',\n",
       " 'looooot',\n",
       " 'chase',\n",
       " 'scenes',\n",
       " 'tons',\n",
       " 'weird',\n",
       " 'things',\n",
       " 'happen',\n",
       " 'most',\n",
       " 'not',\n",
       " 'explained',\n",
       " 'now',\n",
       " 'personally',\n",
       " 'don',\n",
       " 'trying',\n",
       " 'unravel',\n",
       " 'film',\n",
       " 'every',\n",
       " 'when',\n",
       " 'does',\n",
       " 'give',\n",
       " 'me',\n",
       " 'same',\n",
       " 'clue',\n",
       " 'over',\n",
       " 'again',\n",
       " 'kind',\n",
       " 'fed',\n",
       " 'up',\n",
       " 'after',\n",
       " 'while',\n",
       " 'biggest',\n",
       " 'obviously',\n",
       " 'got',\n",
       " 'big',\n",
       " 'secret',\n",
       " 'hide',\n",
       " 'seems',\n",
       " 'want',\n",
       " 'completely',\n",
       " 'until',\n",
       " 'final',\n",
       " 'five',\n",
       " 'minutes',\n",
       " 'do',\n",
       " 'make',\n",
       " 'entertaining',\n",
       " 'thrilling',\n",
       " 'or',\n",
       " 'engaging',\n",
       " 'meantime',\n",
       " 'really',\n",
       " 'sad',\n",
       " 'part',\n",
       " 'arrow',\n",
       " 'both',\n",
       " 'dig',\n",
       " 'flicks',\n",
       " 'we',\n",
       " 'actually',\n",
       " 'figured',\n",
       " 'by',\n",
       " 'half',\n",
       " 'way',\n",
       " 'point',\n",
       " 'strangeness',\n",
       " 'did',\n",
       " 'start',\n",
       " 'little',\n",
       " 'bit',\n",
       " 'sense',\n",
       " 'still',\n",
       " 'more',\n",
       " 'guess',\n",
       " 'bottom',\n",
       " 'line',\n",
       " 'movies',\n",
       " 'should',\n",
       " 'always',\n",
       " 'sure',\n",
       " 'before',\n",
       " 'given',\n",
       " 'password',\n",
       " 'enter',\n",
       " 'understanding',\n",
       " 'mean',\n",
       " 'showing',\n",
       " 'melissa',\n",
       " 'sagemiller',\n",
       " 'running',\n",
       " 'away',\n",
       " 'visions',\n",
       " 'about',\n",
       " '20',\n",
       " 'throughout',\n",
       " 'plain',\n",
       " 'lazy',\n",
       " '!',\n",
       " 'okay',\n",
       " 'people',\n",
       " 'chasing',\n",
       " 'know',\n",
       " 'need',\n",
       " 'how',\n",
       " 'giving',\n",
       " 'us',\n",
       " 'different',\n",
       " 'offering',\n",
       " 'further',\n",
       " 'insight',\n",
       " 'down',\n",
       " 'apparently',\n",
       " 'studio',\n",
       " 'took',\n",
       " 'director',\n",
       " 'chopped',\n",
       " 'themselves',\n",
       " 'shows',\n",
       " 'might',\n",
       " 've',\n",
       " 'been',\n",
       " 'decent',\n",
       " 'here',\n",
       " 'somewhere',\n",
       " 'suits',\n",
       " 'decided',\n",
       " 'turning',\n",
       " 'music',\n",
       " 'video',\n",
       " 'edge',\n",
       " 'would',\n",
       " 'actors',\n",
       " 'although',\n",
       " 'wes',\n",
       " 'bentley',\n",
       " 'seemed',\n",
       " 'be',\n",
       " 'playing',\n",
       " 'exact',\n",
       " 'character',\n",
       " 'he',\n",
       " 'american',\n",
       " 'beauty',\n",
       " 'only',\n",
       " 'new',\n",
       " 'neighborhood',\n",
       " 'my',\n",
       " 'kudos',\n",
       " 'holds',\n",
       " 'own',\n",
       " 'entire',\n",
       " 'feeling',\n",
       " 'unraveling',\n",
       " 'overall',\n",
       " 'doesn',\n",
       " 'stick',\n",
       " 'because',\n",
       " 'entertain',\n",
       " 'confusing',\n",
       " 'rarely',\n",
       " 'excites',\n",
       " 'feels',\n",
       " 'redundant',\n",
       " 'runtime',\n",
       " 'despite',\n",
       " 'ending',\n",
       " 'explanation',\n",
       " 'craziness',\n",
       " 'came',\n",
       " 'oh',\n",
       " 'horror',\n",
       " 'slasher',\n",
       " 'flick',\n",
       " 'packaged',\n",
       " 'someone',\n",
       " 'assuming',\n",
       " 'genre',\n",
       " 'hot',\n",
       " 'kids',\n",
       " 'also',\n",
       " 'wrapped',\n",
       " 'production',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'sitting',\n",
       " 'shelves',\n",
       " 'ever',\n",
       " 'whatever',\n",
       " 'skip',\n",
       " 'where',\n",
       " 'joblo',\n",
       " 'nightmare',\n",
       " 'elm',\n",
       " 'street',\n",
       " '3',\n",
       " '7',\n",
       " '/',\n",
       " '10',\n",
       " 'blair',\n",
       " 'witch',\n",
       " '2',\n",
       " 'crow',\n",
       " '9',\n",
       " 'salvation',\n",
       " '4',\n",
       " 'stir',\n",
       " 'echoes',\n",
       " '8',\n",
       " 'happy',\n",
       " 'bastard',\n",
       " 'quick',\n",
       " 'damn',\n",
       " 'y2k',\n",
       " 'bug',\n",
       " 'starring',\n",
       " 'jamie',\n",
       " 'lee',\n",
       " 'curtis',\n",
       " 'another',\n",
       " 'baldwin',\n",
       " 'brother',\n",
       " 'william',\n",
       " 'time',\n",
       " 'story',\n",
       " 'regarding',\n",
       " 'crew',\n",
       " 'tugboat',\n",
       " 'comes',\n",
       " 'across',\n",
       " 'deserted',\n",
       " 'russian',\n",
       " 'tech',\n",
       " 'ship',\n",
       " 'kick',\n",
       " 'power',\n",
       " 'within',\n",
       " 'gore',\n",
       " 'bringing',\n",
       " 'few',\n",
       " 'action',\n",
       " 'sequences',\n",
       " 'virus',\n",
       " 'empty',\n",
       " 'flash',\n",
       " 'substance',\n",
       " 'why',\n",
       " 'was',\n",
       " 'middle',\n",
       " 'nowhere',\n",
       " 'origin',\n",
       " 'pink',\n",
       " 'flashy',\n",
       " 'thing',\n",
       " 'hit',\n",
       " 'mir',\n",
       " 'course',\n",
       " 'donald',\n",
       " 'sutherland',\n",
       " 'stumbling',\n",
       " 'around',\n",
       " 'drunkenly',\n",
       " 'hey',\n",
       " 'let',\n",
       " 'some',\n",
       " 'robots',\n",
       " 'acting',\n",
       " 'below',\n",
       " 'average',\n",
       " 'likes',\n",
       " 're',\n",
       " 'likely',\n",
       " 'work',\n",
       " 'halloween',\n",
       " 'h20',\n",
       " 'wasted',\n",
       " 'real',\n",
       " 'star',\n",
       " 'stan',\n",
       " 'winston',\n",
       " 'robot',\n",
       " 'design',\n",
       " 'schnazzy',\n",
       " 'cgi',\n",
       " 'occasional',\n",
       " 'shot',\n",
       " 'picking',\n",
       " 'brain',\n",
       " 'if',\n",
       " 'body',\n",
       " 'parts',\n",
       " 'turn',\n",
       " 'otherwise',\n",
       " 'much',\n",
       " 'sunken',\n",
       " 'jaded',\n",
       " 'viewer',\n",
       " 'thankful',\n",
       " 'invention',\n",
       " 'timex',\n",
       " 'indiglo',\n",
       " 'based',\n",
       " 'late',\n",
       " '1960',\n",
       " 'television',\n",
       " 'show',\n",
       " 'name',\n",
       " 'mod',\n",
       " 'squad',\n",
       " 'tells',\n",
       " 'tale',\n",
       " 'three',\n",
       " 'reformed',\n",
       " 'criminals',\n",
       " 'under',\n",
       " 'employ',\n",
       " 'police',\n",
       " 'undercover',\n",
       " 'however',\n",
       " 'wrong',\n",
       " 'evidence',\n",
       " 'gets',\n",
       " 'stolen',\n",
       " 'immediately',\n",
       " 'suspicion',\n",
       " 'ads',\n",
       " 'cuts',\n",
       " 'claire',\n",
       " 'dane',\n",
       " 'nice',\n",
       " 'hair',\n",
       " 'cute',\n",
       " 'outfits',\n",
       " 'car',\n",
       " 'chases',\n",
       " 'stuff',\n",
       " 'blowing',\n",
       " 'sounds',\n",
       " 'first',\n",
       " 'fifteen',\n",
       " 'quickly',\n",
       " 'becomes',\n",
       " 'apparent',\n",
       " 'certainly',\n",
       " 'slick',\n",
       " 'looking',\n",
       " 'complete',\n",
       " 'costumes',\n",
       " 'isn',\n",
       " 'enough',\n",
       " 'best',\n",
       " 'described',\n",
       " 'cross',\n",
       " 'between',\n",
       " 'hour',\n",
       " 'long',\n",
       " 'cop',\n",
       " 'stretched',\n",
       " 'span',\n",
       " 'single',\n",
       " 'clich',\n",
       " 'matter',\n",
       " 'elements',\n",
       " 'recycled',\n",
       " 'everything',\n",
       " 'already',\n",
       " 'seen',\n",
       " 'nothing',\n",
       " 'spectacular',\n",
       " 'sometimes',\n",
       " 'bordering',\n",
       " 'wooden',\n",
       " 'danes',\n",
       " 'omar',\n",
       " 'epps',\n",
       " 'deliver',\n",
       " 'their',\n",
       " 'lines',\n",
       " 'bored',\n",
       " 'transfers',\n",
       " 'onto',\n",
       " 'escape',\n",
       " 'relatively',\n",
       " 'unscathed',\n",
       " 'giovanni',\n",
       " 'ribisi',\n",
       " 'plays',\n",
       " 'resident',\n",
       " 'crazy',\n",
       " 'man',\n",
       " 'ultimately',\n",
       " 'being',\n",
       " 'worth',\n",
       " 'watching',\n",
       " 'unfortunately',\n",
       " 'save',\n",
       " 'convoluted',\n",
       " 'apart',\n",
       " 'occupying',\n",
       " 'screen',\n",
       " 'young',\n",
       " 'cast',\n",
       " 'clothes',\n",
       " 'hip',\n",
       " 'soundtrack',\n",
       " 'appears',\n",
       " 'geared',\n",
       " 'towards',\n",
       " 'teenage',\n",
       " 'mindset',\n",
       " 'r',\n",
       " 'rating',\n",
       " 'content',\n",
       " 'justify',\n",
       " 'juvenile',\n",
       " 'older',\n",
       " 'information',\n",
       " 'literally',\n",
       " 'spoon',\n",
       " 'hard',\n",
       " 'instead',\n",
       " 'telling',\n",
       " 'dialogue',\n",
       " 'poorly',\n",
       " 'written',\n",
       " 'extremely',\n",
       " 'predictable',\n",
       " 'progresses',\n",
       " 'won',\n",
       " 'care',\n",
       " 'heroes',\n",
       " 'any',\n",
       " 'jeopardy',\n",
       " 'll',\n",
       " 'aren',\n",
       " 'basing',\n",
       " 'nobody',\n",
       " 'remembers',\n",
       " 'questionable',\n",
       " 'wisdom',\n",
       " 'especially',\n",
       " 'considers',\n",
       " 'target',\n",
       " 'fact',\n",
       " 'number',\n",
       " 'memorable',\n",
       " 'can',\n",
       " 'counted',\n",
       " 'hand',\n",
       " 'missing',\n",
       " 'finger',\n",
       " 'times',\n",
       " 'checked',\n",
       " 'six',\n",
       " 'clear',\n",
       " 'indication',\n",
       " 'them',\n",
       " 'than',\n",
       " 'cash',\n",
       " 'spending',\n",
       " 'dollar',\n",
       " 'judging',\n",
       " 'rash',\n",
       " 'awful',\n",
       " 'seeing',\n",
       " 'avoid',\n",
       " 'at',\n",
       " 'costs',\n",
       " 'quest',\n",
       " 'camelot',\n",
       " 'warner',\n",
       " 'bros',\n",
       " 'feature',\n",
       " 'length',\n",
       " 'fully',\n",
       " 'animated',\n",
       " 'steal',\n",
       " 'clout',\n",
       " 'disney',\n",
       " 'cartoon',\n",
       " 'empire',\n",
       " 'mouse',\n",
       " 'reason',\n",
       " 'worried',\n",
       " 'other',\n",
       " 'recent',\n",
       " 'challenger',\n",
       " 'throne',\n",
       " 'last',\n",
       " 'fall',\n",
       " 'promising',\n",
       " 'flawed',\n",
       " '20th',\n",
       " 'century',\n",
       " 'fox',\n",
       " 'anastasia',\n",
       " 'hercules',\n",
       " 'lively',\n",
       " 'colorful',\n",
       " 'palate',\n",
       " 'had',\n",
       " 'beat',\n",
       " 'hands',\n",
       " 'crown',\n",
       " '1997',\n",
       " 'piece',\n",
       " 'animation',\n",
       " 'year',\n",
       " 'contest',\n",
       " 'arrival',\n",
       " 'magic',\n",
       " 'kingdom',\n",
       " 'mediocre',\n",
       " '--',\n",
       " 'd',\n",
       " 'pocahontas',\n",
       " 'those',\n",
       " 'keeping',\n",
       " 'score',\n",
       " 'nearly',\n",
       " 'dull',\n",
       " 'revolves',\n",
       " 'adventures',\n",
       " 'free',\n",
       " 'spirited',\n",
       " 'kayley',\n",
       " 'voiced',\n",
       " 'jessalyn',\n",
       " 'gilsig',\n",
       " 'early',\n",
       " 'daughter',\n",
       " 'belated',\n",
       " 'knight',\n",
       " 'king',\n",
       " 'arthur',\n",
       " 'round',\n",
       " 'table',\n",
       " 'dream',\n",
       " 'follow',\n",
       " 'father',\n",
       " 'footsteps',\n",
       " 'she',\n",
       " 'chance',\n",
       " 'evil',\n",
       " 'warlord',\n",
       " 'ruber',\n",
       " 'gary',\n",
       " 'oldman',\n",
       " 'ex',\n",
       " 'gone',\n",
       " 'steals',\n",
       " 'magical',\n",
       " 'sword',\n",
       " 'excalibur',\n",
       " 'accidentally',\n",
       " 'loses',\n",
       " 'dangerous',\n",
       " 'booby',\n",
       " 'trapped',\n",
       " 'forest',\n",
       " 'help',\n",
       " 'hunky',\n",
       " 'blind',\n",
       " 'timberland',\n",
       " 'dweller',\n",
       " 'garrett',\n",
       " 'carey',\n",
       " 'elwes',\n",
       " 'headed',\n",
       " 'dragon',\n",
       " 'eric',\n",
       " 'idle',\n",
       " 'rickles',\n",
       " 'arguing',\n",
       " 'itself',\n",
       " 'able',\n",
       " 'medieval',\n",
       " 'sexist',\n",
       " 'prove',\n",
       " 'fighter',\n",
       " 'side',\n",
       " 'pure',\n",
       " 'showmanship',\n",
       " 'essential',\n",
       " 'element',\n",
       " 'expected',\n",
       " 'climb',\n",
       " 'high',\n",
       " 'ranks',\n",
       " 'differentiates',\n",
       " 'something',\n",
       " 'saturday',\n",
       " 'morning',\n",
       " 'subpar',\n",
       " 'instantly',\n",
       " 'forgettable',\n",
       " 'songs',\n",
       " 'integrated',\n",
       " 'computerized',\n",
       " 'footage',\n",
       " 'compare',\n",
       " 'run',\n",
       " 'angry',\n",
       " 'ogre',\n",
       " 'herc',\n",
       " 'battle',\n",
       " 'hydra',\n",
       " 'rest',\n",
       " 'case',\n",
       " 'stink',\n",
       " 'none',\n",
       " 'remotely',\n",
       " 'interesting',\n",
       " 'race',\n",
       " 'bland',\n",
       " 'end',\n",
       " 'tie',\n",
       " 'win',\n",
       " 'comedy',\n",
       " 'shtick',\n",
       " 'awfully',\n",
       " 'cloying',\n",
       " 'least',\n",
       " 'signs',\n",
       " 'pulse',\n",
       " 'fans',\n",
       " \"-'\",\n",
       " '90s',\n",
       " 'tgif',\n",
       " 'will',\n",
       " 'thrilled',\n",
       " 'jaleel',\n",
       " 'urkel',\n",
       " 'white',\n",
       " 'bronson',\n",
       " 'balki',\n",
       " 'pinchot',\n",
       " 'sharing',\n",
       " 'nicely',\n",
       " 'realized',\n",
       " 'though',\n",
       " 'm',\n",
       " 'loss',\n",
       " 'recall',\n",
       " 'specific',\n",
       " 'providing',\n",
       " 'voice',\n",
       " 'talent',\n",
       " 'enthusiastic',\n",
       " 'paired',\n",
       " 'singers',\n",
       " 'sound',\n",
       " 'musical',\n",
       " 'moments',\n",
       " 'jane',\n",
       " 'seymour',\n",
       " 'celine',\n",
       " 'dion',\n",
       " 'must',\n",
       " 'strain',\n",
       " 'through',\n",
       " 'aside',\n",
       " 'children',\n",
       " 'probably',\n",
       " 'adults',\n",
       " 'grievous',\n",
       " 'error',\n",
       " 'lack',\n",
       " 'personality',\n",
       " 'learn',\n",
       " 'goes',\n",
       " 'synopsis',\n",
       " 'mentally',\n",
       " 'unstable',\n",
       " 'undergoing',\n",
       " 'psychotherapy',\n",
       " 'saves',\n",
       " 'boy',\n",
       " 'potentially',\n",
       " 'fatal',\n",
       " 'falls',\n",
       " 'love',\n",
       " 'mother',\n",
       " 'fledgling',\n",
       " 'restauranteur',\n",
       " 'unsuccessfully',\n",
       " 'attempting',\n",
       " 'gain',\n",
       " 'woman',\n",
       " 'favor',\n",
       " 'takes',\n",
       " 'pictures',\n",
       " 'kills',\n",
       " 'comments',\n",
       " 'stalked',\n",
       " 'yet',\n",
       " 'seemingly',\n",
       " 'endless',\n",
       " 'string',\n",
       " 'spurned',\n",
       " 'psychos',\n",
       " 'getting',\n",
       " 'revenge',\n",
       " 'type',\n",
       " 'stable',\n",
       " 'category',\n",
       " '1990s',\n",
       " 'industry',\n",
       " 'theatrical',\n",
       " 'direct',\n",
       " 'proliferation',\n",
       " 'may',\n",
       " 'due',\n",
       " 'typically',\n",
       " 'inexpensive',\n",
       " 'produce',\n",
       " 'special',\n",
       " 'effects',\n",
       " 'stars',\n",
       " 'serve',\n",
       " 'vehicles',\n",
       " 'nudity',\n",
       " 'allowing',\n",
       " 'frequent',\n",
       " 'night',\n",
       " 'cable',\n",
       " 'wavers',\n",
       " 'slightly',\n",
       " 'norm',\n",
       " 'respect',\n",
       " 'psycho',\n",
       " 'never',\n",
       " 'affair',\n",
       " ';',\n",
       " 'contrary',\n",
       " 'rejected',\n",
       " 'rather',\n",
       " 'lover',\n",
       " 'wife',\n",
       " 'husband',\n",
       " 'entry',\n",
       " 'doomed',\n",
       " 'collect',\n",
       " 'dust',\n",
       " 'viewed',\n",
       " 'midnight',\n",
       " 'provide',\n",
       " 'suspense',\n",
       " 'sets',\n",
       " 'interspersed',\n",
       " 'opening',\n",
       " 'credits',\n",
       " 'instance',\n",
       " 'serious',\n",
       " 'sounding',\n",
       " 'narrator',\n",
       " 'spouts',\n",
       " 'statistics',\n",
       " 'stalkers',\n",
       " 'ponders',\n",
       " 'cause',\n",
       " 'stalk',\n",
       " 'implicitly',\n",
       " 'implied',\n",
       " 'men',\n",
       " 'shown',\n",
       " 'snapshot',\n",
       " 'actor',\n",
       " 'jay',\n",
       " 'underwood',\n",
       " 'states',\n",
       " 'daryl',\n",
       " 'gleason',\n",
       " 'stalker',\n",
       " 'brooke',\n",
       " 'daniels',\n",
       " 'meant',\n",
       " 'called',\n",
       " 'guesswork',\n",
       " 'required',\n",
       " 'proceeds',\n",
       " 'begins',\n",
       " 'obvious',\n",
       " 'sequence',\n",
       " 'contrived',\n",
       " 'quite',\n",
       " 'brings',\n",
       " 'victim',\n",
       " 'together',\n",
       " 'obsesses',\n",
       " 'follows',\n",
       " 'tries',\n",
       " 'woo',\n",
       " 'plans',\n",
       " 'become',\n",
       " 'desperate',\n",
       " 'elaborate',\n",
       " 'include',\n",
       " 'cliche',\n",
       " 'murdered',\n",
       " 'pet',\n",
       " 'require',\n",
       " 'found',\n",
       " 'exception',\n",
       " 'cat',\n",
       " 'shower',\n",
       " 'events',\n",
       " 'lead',\n",
       " 'inevitable',\n",
       " 'showdown',\n",
       " 'survives',\n",
       " 'invariably',\n",
       " 'conclusion',\n",
       " 'turkey',\n",
       " 'uniformly',\n",
       " 'adequate',\n",
       " 'anything',\n",
       " 'home',\n",
       " 'either',\n",
       " 'turns',\n",
       " 'toward',\n",
       " 'melodrama',\n",
       " 'overdoes',\n",
       " 'words',\n",
       " 'manages',\n",
       " 'creepy',\n",
       " 'pass',\n",
       " 'demands',\n",
       " 'maryam',\n",
       " 'abo',\n",
       " 'close',\n",
       " 'played',\n",
       " 'bond',\n",
       " 'chick',\n",
       " 'living',\n",
       " 'daylights',\n",
       " 'equally',\n",
       " 'title',\n",
       " 'ditzy',\n",
       " 'strong',\n",
       " 'independent',\n",
       " 'business',\n",
       " 'owner',\n",
       " 'needs',\n",
       " 'proceed',\n",
       " 'example',\n",
       " 'suspicions',\n",
       " 'ensure',\n",
       " 'use',\n",
       " 'excuse',\n",
       " 'decides',\n",
       " 'return',\n",
       " 'toolbox',\n",
       " 'left',\n",
       " 'place',\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features = list(all_words.keys())[:3000]; word_features\n",
    "# 3000개만 잘라서 봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "# parameter로 주어지는 document에 word features의 단어가 들어있으면 True 아니면 False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plot': True, ':': True, 'two': True, 'teen': True, 'couples': True, 'go': True, 'to': True, 'a': True, 'church': True, 'party': True, ',': True, 'drink': True, 'and': True, 'then': True, 'drive': True, '.': True, 'they': True, 'get': True, 'into': True, 'an': True, 'accident': True, 'one': True, 'of': True, 'the': True, 'guys': True, 'dies': True, 'but': True, 'his': True, 'girlfriend': True, 'continues': True, 'see': True, 'him': True, 'in': True, 'her': True, 'life': True, 'has': True, 'nightmares': True, 'what': True, \"'\": True, 's': True, 'deal': True, '?': True, 'watch': True, 'movie': True, '\"': True, 'sorta': True, 'find': True, 'out': True, 'critique': True, 'mind': True, '-': True, 'fuck': True, 'for': True, 'generation': True, 'that': True, 'touches': True, 'on': True, 'very': True, 'cool': True, 'idea': True, 'presents': True, 'it': True, 'bad': True, 'package': True, 'which': True, 'is': True, 'makes': True, 'this': True, 'review': True, 'even': True, 'harder': True, 'write': True, 'since': True, 'i': True, 'generally': True, 'applaud': True, 'films': True, 'attempt': True, 'break': True, 'mold': True, 'mess': True, 'with': True, 'your': True, 'head': True, 'such': True, '(': True, 'lost': True, 'highway': True, '&': True, 'memento': True, ')': True, 'there': True, 'are': True, 'good': True, 'ways': True, 'making': True, 'all': True, 'types': True, 'these': True, 'folks': True, 'just': True, 'didn': True, 't': True, 'snag': True, 'correctly': True, 'seem': True, 'have': True, 'taken': True, 'pretty': True, 'neat': True, 'concept': True, 'executed': True, 'terribly': True, 'so': True, 'problems': True, 'well': True, 'its': True, 'main': True, 'problem': True, 'simply': True, 'too': True, 'jumbled': True, 'starts': True, 'off': True, 'normal': True, 'downshifts': True, 'fantasy': True, 'world': True, 'you': True, 'as': True, 'audience': True, 'member': True, 'no': True, 'going': True, 'dreams': True, 'characters': True, 'coming': True, 'back': True, 'from': True, 'dead': True, 'others': True, 'who': True, 'look': True, 'like': True, 'strange': True, 'apparitions': True, 'disappearances': True, 'looooot': True, 'chase': True, 'scenes': True, 'tons': True, 'weird': True, 'things': True, 'happen': True, 'most': True, 'not': True, 'explained': True, 'now': True, 'personally': True, 'don': True, 'trying': True, 'unravel': True, 'film': True, 'every': True, 'when': True, 'does': True, 'give': True, 'me': True, 'same': True, 'clue': True, 'over': True, 'again': True, 'kind': True, 'fed': True, 'up': True, 'after': True, 'while': True, 'biggest': True, 'obviously': True, 'got': True, 'big': True, 'secret': True, 'hide': True, 'seems': True, 'want': True, 'completely': True, 'until': True, 'final': True, 'five': True, 'minutes': True, 'do': True, 'make': True, 'entertaining': True, 'thrilling': True, 'or': True, 'engaging': True, 'meantime': True, 'really': True, 'sad': True, 'part': True, 'arrow': True, 'both': True, 'dig': True, 'flicks': True, 'we': True, 'actually': True, 'figured': True, 'by': True, 'half': True, 'way': True, 'point': True, 'strangeness': True, 'did': True, 'start': True, 'little': True, 'bit': True, 'sense': True, 'still': True, 'more': True, 'guess': True, 'bottom': True, 'line': True, 'movies': True, 'should': True, 'always': True, 'sure': True, 'before': True, 'given': True, 'password': True, 'enter': True, 'understanding': True, 'mean': True, 'showing': True, 'melissa': True, 'sagemiller': True, 'running': True, 'away': True, 'visions': True, 'about': True, '20': True, 'throughout': True, 'plain': True, 'lazy': True, '!': True, 'okay': True, 'people': True, 'chasing': True, 'know': True, 'need': True, 'how': True, 'giving': True, 'us': True, 'different': True, 'offering': True, 'further': True, 'insight': True, 'down': True, 'apparently': True, 'studio': True, 'took': True, 'director': True, 'chopped': True, 'themselves': True, 'shows': True, 'might': True, 've': True, 'been': True, 'decent': True, 'here': True, 'somewhere': True, 'suits': True, 'decided': True, 'turning': True, 'music': True, 'video': True, 'edge': True, 'would': True, 'actors': True, 'although': True, 'wes': True, 'bentley': True, 'seemed': True, 'be': True, 'playing': True, 'exact': True, 'character': True, 'he': True, 'american': True, 'beauty': True, 'only': True, 'new': True, 'neighborhood': True, 'my': True, 'kudos': True, 'holds': True, 'own': True, 'entire': True, 'feeling': True, 'unraveling': True, 'overall': True, 'doesn': True, 'stick': True, 'because': True, 'entertain': True, 'confusing': True, 'rarely': True, 'excites': True, 'feels': True, 'redundant': True, 'runtime': True, 'despite': True, 'ending': True, 'explanation': True, 'craziness': True, 'came': True, 'oh': True, 'horror': True, 'slasher': True, 'flick': True, 'packaged': True, 'someone': True, 'assuming': True, 'genre': True, 'hot': True, 'kids': True, 'also': True, 'wrapped': True, 'production': True, 'years': True, 'ago': True, 'sitting': True, 'shelves': True, 'ever': True, 'whatever': True, 'skip': True, 'where': True, 'joblo': True, 'nightmare': True, 'elm': True, 'street': True, '3': True, '7': True, '/': True, '10': True, 'blair': True, 'witch': True, '2': True, 'crow': True, '9': True, 'salvation': True, '4': True, 'stir': True, 'echoes': True, '8': True, 'happy': False, 'bastard': False, 'quick': False, 'damn': False, 'y2k': False, 'bug': False, 'starring': False, 'jamie': False, 'lee': False, 'curtis': False, 'another': False, 'baldwin': False, 'brother': False, 'william': False, 'time': False, 'story': False, 'regarding': False, 'crew': False, 'tugboat': False, 'comes': False, 'across': False, 'deserted': False, 'russian': False, 'tech': False, 'ship': False, 'kick': False, 'power': False, 'within': False, 'gore': False, 'bringing': False, 'few': False, 'action': False, 'sequences': False, 'virus': False, 'empty': False, 'flash': False, 'substance': False, 'why': False, 'was': False, 'middle': False, 'nowhere': False, 'origin': False, 'pink': False, 'flashy': False, 'thing': False, 'hit': False, 'mir': False, 'course': False, 'donald': False, 'sutherland': False, 'stumbling': False, 'around': False, 'drunkenly': False, 'hey': False, 'let': False, 'some': False, 'robots': False, 'acting': False, 'below': False, 'average': False, 'likes': False, 're': False, 'likely': False, 'work': False, 'halloween': False, 'h20': False, 'wasted': False, 'real': False, 'star': False, 'stan': False, 'winston': False, 'robot': False, 'design': False, 'schnazzy': False, 'cgi': False, 'occasional': False, 'shot': False, 'picking': False, 'brain': False, 'if': False, 'body': False, 'parts': False, 'turn': False, 'otherwise': False, 'much': False, 'sunken': False, 'jaded': False, 'viewer': False, 'thankful': False, 'invention': False, 'timex': False, 'indiglo': False, 'based': False, 'late': False, '1960': False, 'television': False, 'show': False, 'name': False, 'mod': False, 'squad': False, 'tells': False, 'tale': False, 'three': False, 'reformed': False, 'criminals': False, 'under': False, 'employ': False, 'police': False, 'undercover': False, 'however': False, 'wrong': False, 'evidence': False, 'gets': False, 'stolen': False, 'immediately': False, 'suspicion': False, 'ads': False, 'cuts': False, 'claire': False, 'dane': False, 'nice': False, 'hair': False, 'cute': False, 'outfits': False, 'car': False, 'chases': False, 'stuff': False, 'blowing': False, 'sounds': False, 'first': False, 'fifteen': False, 'quickly': False, 'becomes': False, 'apparent': False, 'certainly': False, 'slick': False, 'looking': False, 'complete': False, 'costumes': False, 'isn': False, 'enough': False, 'best': False, 'described': False, 'cross': False, 'between': False, 'hour': False, 'long': False, 'cop': False, 'stretched': False, 'span': False, 'single': False, 'clich': False, 'matter': False, 'elements': False, 'recycled': False, 'everything': False, 'already': False, 'seen': False, 'nothing': False, 'spectacular': False, 'sometimes': False, 'bordering': False, 'wooden': False, 'danes': False, 'omar': False, 'epps': False, 'deliver': False, 'their': False, 'lines': False, 'bored': False, 'transfers': False, 'onto': False, 'escape': False, 'relatively': False, 'unscathed': False, 'giovanni': False, 'ribisi': False, 'plays': False, 'resident': False, 'crazy': False, 'man': False, 'ultimately': False, 'being': False, 'worth': False, 'watching': False, 'unfortunately': False, 'save': False, 'convoluted': False, 'apart': False, 'occupying': False, 'screen': False, 'young': False, 'cast': False, 'clothes': False, 'hip': False, 'soundtrack': False, 'appears': False, 'geared': False, 'towards': False, 'teenage': False, 'mindset': False, 'r': False, 'rating': False, 'content': False, 'justify': False, 'juvenile': False, 'older': False, 'information': False, 'literally': False, 'spoon': False, 'hard': False, 'instead': False, 'telling': False, 'dialogue': False, 'poorly': False, 'written': False, 'extremely': False, 'predictable': False, 'progresses': False, 'won': False, 'care': False, 'heroes': False, 'any': False, 'jeopardy': False, 'll': False, 'aren': False, 'basing': False, 'nobody': False, 'remembers': False, 'questionable': False, 'wisdom': False, 'especially': False, 'considers': False, 'target': False, 'fact': False, 'number': False, 'memorable': False, 'can': False, 'counted': False, 'hand': False, 'missing': False, 'finger': False, 'times': False, 'checked': False, 'six': False, 'clear': False, 'indication': False, 'them': False, 'than': False, 'cash': False, 'spending': False, 'dollar': False, 'judging': False, 'rash': False, 'awful': False, 'seeing': False, 'avoid': False, 'at': False, 'costs': False, 'quest': False, 'camelot': False, 'warner': False, 'bros': False, 'feature': False, 'length': False, 'fully': False, 'animated': False, 'steal': False, 'clout': False, 'disney': False, 'cartoon': False, 'empire': False, 'mouse': False, 'reason': False, 'worried': False, 'other': False, 'recent': False, 'challenger': False, 'throne': False, 'last': False, 'fall': False, 'promising': False, 'flawed': False, '20th': False, 'century': False, 'fox': False, 'anastasia': False, 'hercules': False, 'lively': False, 'colorful': False, 'palate': False, 'had': False, 'beat': False, 'hands': False, 'crown': False, '1997': False, 'piece': False, 'animation': False, 'year': False, 'contest': False, 'arrival': False, 'magic': False, 'kingdom': False, 'mediocre': False, '--': False, 'd': False, 'pocahontas': False, 'those': False, 'keeping': False, 'score': False, 'nearly': False, 'dull': False, 'revolves': False, 'adventures': False, 'free': False, 'spirited': False, 'kayley': False, 'voiced': False, 'jessalyn': False, 'gilsig': False, 'early': False, 'daughter': False, 'belated': False, 'knight': False, 'king': False, 'arthur': False, 'round': False, 'table': False, 'dream': False, 'follow': False, 'father': False, 'footsteps': False, 'she': False, 'chance': False, 'evil': False, 'warlord': False, 'ruber': False, 'gary': False, 'oldman': False, 'ex': False, 'gone': False, 'steals': False, 'magical': False, 'sword': False, 'excalibur': False, 'accidentally': False, 'loses': False, 'dangerous': False, 'booby': False, 'trapped': False, 'forest': False, 'help': False, 'hunky': False, 'blind': False, 'timberland': False, 'dweller': False, 'garrett': False, 'carey': False, 'elwes': False, 'headed': False, 'dragon': False, 'eric': False, 'idle': False, 'rickles': False, 'arguing': False, 'itself': False, 'able': False, 'medieval': False, 'sexist': False, 'prove': False, 'fighter': False, 'side': False, 'pure': False, 'showmanship': False, 'essential': False, 'element': False, 'expected': False, 'climb': False, 'high': False, 'ranks': False, 'differentiates': False, 'something': False, 'saturday': False, 'morning': False, 'subpar': False, 'instantly': False, 'forgettable': False, 'songs': False, 'integrated': False, 'computerized': False, 'footage': False, 'compare': False, 'run': False, 'angry': False, 'ogre': False, 'herc': False, 'battle': False, 'hydra': False, 'rest': False, 'case': False, 'stink': False, 'none': False, 'remotely': False, 'interesting': False, 'race': False, 'bland': False, 'end': False, 'tie': False, 'win': False, 'comedy': False, 'shtick': False, 'awfully': False, 'cloying': False, 'least': False, 'signs': False, 'pulse': False, 'fans': False, \"-'\": False, '90s': False, 'tgif': False, 'will': False, 'thrilled': False, 'jaleel': False, 'urkel': False, 'white': False, 'bronson': False, 'balki': False, 'pinchot': False, 'sharing': False, 'nicely': False, 'realized': False, 'though': False, 'm': False, 'loss': False, 'recall': False, 'specific': False, 'providing': False, 'voice': False, 'talent': False, 'enthusiastic': False, 'paired': False, 'singers': False, 'sound': False, 'musical': False, 'moments': False, 'jane': False, 'seymour': False, 'celine': False, 'dion': False, 'must': False, 'strain': False, 'through': False, 'aside': False, 'children': False, 'probably': False, 'adults': False, 'grievous': False, 'error': False, 'lack': False, 'personality': False, 'learn': False, 'goes': False, 'synopsis': False, 'mentally': False, 'unstable': False, 'undergoing': False, 'psychotherapy': False, 'saves': False, 'boy': False, 'potentially': False, 'fatal': False, 'falls': False, 'love': False, 'mother': False, 'fledgling': False, 'restauranteur': False, 'unsuccessfully': False, 'attempting': False, 'gain': False, 'woman': False, 'favor': False, 'takes': False, 'pictures': False, 'kills': False, 'comments': False, 'stalked': False, 'yet': False, 'seemingly': False, 'endless': False, 'string': False, 'spurned': False, 'psychos': False, 'getting': False, 'revenge': False, 'type': False, 'stable': False, 'category': False, '1990s': False, 'industry': False, 'theatrical': False, 'direct': False, 'proliferation': False, 'may': False, 'due': False, 'typically': False, 'inexpensive': False, 'produce': False, 'special': False, 'effects': False, 'stars': False, 'serve': False, 'vehicles': False, 'nudity': False, 'allowing': False, 'frequent': False, 'night': False, 'cable': False, 'wavers': False, 'slightly': False, 'norm': False, 'respect': False, 'psycho': False, 'never': False, 'affair': False, ';': False, 'contrary': False, 'rejected': False, 'rather': False, 'lover': False, 'wife': False, 'husband': False, 'entry': False, 'doomed': False, 'collect': False, 'dust': False, 'viewed': False, 'midnight': False, 'provide': False, 'suspense': False, 'sets': False, 'interspersed': False, 'opening': False, 'credits': False, 'instance': False, 'serious': False, 'sounding': False, 'narrator': False, 'spouts': False, 'statistics': False, 'stalkers': False, 'ponders': False, 'cause': False, 'stalk': False, 'implicitly': False, 'implied': False, 'men': False, 'shown': False, 'snapshot': False, 'actor': False, 'jay': False, 'underwood': False, 'states': False, 'daryl': False, 'gleason': False, 'stalker': False, 'brooke': False, 'daniels': False, 'meant': False, 'called': False, 'guesswork': False, 'required': False, 'proceeds': False, 'begins': False, 'obvious': False, 'sequence': False, 'contrived': False, 'quite': False, 'brings': False, 'victim': False, 'together': False, 'obsesses': False, 'follows': False, 'tries': False, 'woo': False, 'plans': False, 'become': False, 'desperate': False, 'elaborate': False, 'include': False, 'cliche': False, 'murdered': False, 'pet': False, 'require': False, 'found': False, 'exception': False, 'cat': False, 'shower': False, 'events': False, 'lead': False, 'inevitable': False, 'showdown': False, 'survives': False, 'invariably': False, 'conclusion': False, 'turkey': False, 'uniformly': False, 'adequate': False, 'anything': False, 'home': False, 'either': False, 'turns': False, 'toward': False, 'melodrama': False, 'overdoes': False, 'words': False, 'manages': False, 'creepy': False, 'pass': False, 'demands': False, 'maryam': False, 'abo': False, 'close': False, 'played': False, 'bond': False, 'chick': False, 'living': False, 'daylights': False, 'equally': False, 'title': False, 'ditzy': False, 'strong': False, 'independent': False, 'business': False, 'owner': False, 'needs': False, 'proceed': False, 'example': False, 'suspicions': False, 'ensure': False, 'use': False, 'excuse': False, 'decides': False, 'return': False, 'toolbox': False, 'left': False, 'place': False, 'house': False, 'leave': False, 'door': False, 'answers': False, 'opens': False, 'wanders': False, 'returns': False, 'enters': False, 'our': False, 'heroine': False, 'danger': False, 'somehow': False, 'parked': False, 'front': False, 'right': False, 'oblivious': False, 'presence': False, 'inside': False, 'whole': False, 'episode': False, 'places': False, 'incredible': False, 'suspension': False, 'disbelief': False, 'questions': False, 'validity': False, 'intelligence': False, 'receives': False, 'highly': False, 'derivative': False, 'somewhat': False, 'boring': False, 'cannot': False, 'watched': False, 'rated': False, 'mostly': False, 'several': False, 'murder': False, 'brief': False, 'strip': False, 'bar': False, 'offensive': False, 'many': False, 'thrillers': False, 'mood': False, 'stake': False, 'else': False, 'capsule': False, '2176': False, 'planet': False, 'mars': False, 'taking': False, 'custody': False, 'accused': False, 'murderer': False, 'face': False, 'menace': False, 'lot': False, 'fighting': False, 'john': False, 'carpenter': False, 'reprises': False, 'ideas': False, 'previous': False, 'assault': False, 'precinct': False, '13': False, 'homage': False, 'himself': False, '0': False, '+': False, 'believes': False, 'fight': False, 'horrible': False, 'writer': False, 'supposedly': False, 'expert': False, 'mistake': False, 'ghosts': False, 'drawn': False, 'humans': False, 'surprisingly': False, 'low': False, 'powered': False, 'alien': False, 'addition': False, 'anybody': False, 'made': False, 'grounds': False, 'sue': False, 'chock': False, 'full': False, 'pieces': False, 'prince': False, 'darkness': False, 'surprising': False, 'managed': False, 'fit': False, 'admittedly': False, 'novel': False, 'science': False, 'fiction': False, 'experience': False, 'terraformed': False, 'walk': False, 'surface': False, 'without': False, 'breathing': False, 'gear': False, 'budget': False, 'mentioned': False, 'gravity': False, 'increased': False, 'earth': False, 'easier': False, 'society': False, 'changed': False, 'advanced': False, 'culture': False, 'women': False, 'positions': False, 'control': False, 'view': False, 'stagnated': False, 'female': False, 'beyond': False, 'minor': False, 'technological': False, 'advances': False, 'less': False, '175': False, 'expect': False, 'change': False, 'ten': False, 'basic': False, 'common': False, 'except': False, 'yes': False, 'replaced': False, 'tacky': False, 'rundown': False, 'martian': False, 'mining': False, 'colony': False, 'having': False, 'criminal': False, 'napolean': False, 'wilson': False, 'desolation': False, 'williams': False, 'facing': False, 'hoodlums': False, 'automatic': False, 'weapons': False, 'nature': False, 'behave': False, 'manner': False, 'essentially': False, 'human': False, 'savages': False, 'lapse': False, 'imagination': False, 'told': False, 'flashback': False, 'entirely': False, 'filmed': False, 'almost': False, 'tones': False, 'red': False, 'yellow': False, 'black': False, 'powerful': False, 'scene': False, 'train': False, 'rushing': False, 'heavy': False, 'sadly': False, 'buildup': False, 'terror': False, 'creates': False, 'looks': False, 'fugitive': False, 'wannabes': False, 'rock': False, 'band': False, 'kiss': False, 'building': False, 'bunch': False, 'sudden': False, 'jump': False, 'sucker': False, 'thinking': False, 'scary': False, 'happening': False, 'standard': False, 'haunted': False, 'shock': False, 'great': False, 'newer': False, 'unimpressive': False, 'digital': False, 'decapitations': False, 'fights': False, 'short': False, 'stretch': False, 'release': False, 'mission': False, 'panned': False, 'reviewers': False, 'better': False, 'rate': False, 'scale': False, 'following': False, 'showed': False, 'liked': False, 'moderately': False, 'classic': False, 'comment': False, 'twice': False, 'ask': False, 'yourself': False, '8mm': False, 'eight': False, 'millimeter': False, 'wholesome': False, 'surveillance': False, 'sight': False, 'values': False, 'becoming': False, 'enmeshed': False, 'seedy': False, 'sleazy': False, 'underworld': False, 'hardcore': False, 'pornography': False, 'bubbling': False, 'beneath': False, 'town': False, 'americana': False, 'sordid': False, 'sick': False, 'depraved': False, 'necessarily': False, 'stop': False, 'order': False, 'satisfy': False, 'twisted': False, 'desires': False, 'position': False, 'influence': False, 'kinds': False, 'demented': False, 'talking': False, 'snuff': False, 'supposed': False, 'documentaries': False, 'victims': False, 'brutalized': False, 'killed': False, 'camera': False, 'joel': False, 'schumacher': False, 'credit': False, 'batman': False, 'robin': False, 'kill': False, 'forever': False, 'client': False, 'thirds': False, 'unwind': False, 'fairly': False, 'conventional': False, 'persons': False, 'drama': False, 'albeit': False, 'particularly': False, 'unsavory': False, 'core': False, 'threatening': False, 'along': False, 'explodes': False, 'violence': False, 'think': False, 'finally': False, 'tags': False, 'ridiculous': False, 'self': False, 'righteous': False, 'finale': False, 'drags': False, 'unpleasant': False, 'trust': False, 'waste': False, 'hours': False, 'nicolas': False, 'snake': False, 'eyes': False, 'cage': False, 'private': False, 'investigator': False, 'tom': False, 'welles': False, 'hired': False, 'wealthy': False, 'philadelphia': False, 'widow': False, 'determine': False, 'whether': False, 'reel': False, 'safe': False, 'documents': False, 'girl': False, 'assignment': False, 'factly': False, 'puzzle': False, 'neatly': False, 'specialized': False, 'skills': False, 'training': False, 'easy': False, 'cops': False, 'toilet': False, 'tanks': False, 'clues': False, 'deeper': False, 'digs': False, 'investigation': False, 'obsessed': False, 'george': False, 'c': False, 'scott': False, 'paul': False, 'schrader': False, 'occasionally': False, 'flickering': False, 'whirs': False, 'sprockets': False, 'winding': False, 'projector': False, 'reminding': False, 'task': False, 'hints': False, 'toll': False, 'lovely': False, 'catherine': False, 'keener': False, 'frustrated': False, 'cleveland': False, 'ugly': False, 'split': False, 'level': False, 'harrisburg': False, 'pa': False, 'condemn': False, 'condone': False, 'subject': False, 'exploits': False, 'irony': False, 'seven': False, 'scribe': False, 'andrew': False, 'kevin': False, 'walker': False, 'vision': False, 'lane': False, 'limited': False, 'hollywood': False, 'product': False, 'snippets': False, 'covering': False, 'later': False, 'joaquin': False, 'phoenix': False, 'far': False, 'adult': False, 'bookstore': False, 'flunky': False, 'max': False, 'california': False, 'cover': False, 'horrid': False, 'screened': False, 'familiar': False, 'revelation': False, 'sexual': False, 'deviants': False, 'indeed': False, 'monsters': False, 'everyday': False, 'neither': False, 'super': False, 'nor': False, 'shocking': False, 'banality': False, 'exactly': False, 'felt': False, 'weren': False, 'nine': False, 'laughs': False, 'months': False, 'terrible': False, 'mr': False, 'hugh': False, 'grant': False, 'huge': False, 'dork': False, 'oral': False, 'sex': False, 'prostitution': False, 'referring': False, 'bugs': False, 'annoying': False, 'adam': False, 'sandler': False, 'jim': False, 'carrey': False, 'eye': False, 'flutters': False, 'nervous': False, 'smiles': False, 'slapstick': False, 'fistfight': False, 'delivery': False, 'room': False, 'culminating': False, 'joan': False, 'cusack': False, 'lap': False, 'paid': False, '$': False, '60': False, 'included': False, 'obscene': False, 'double': False, 'entendres': False, 'obstetrician': False, 'pregnant': False, 'pussy': False, 'size': False, 'hairs': False, 'coat': False, 'nonetheless': False, 'exchange': False, 'cookie': False, 'cutter': False, 'originality': False, 'humor': False, 'successful': False, 'child': False, 'psychiatrist': False, 'psychologist': False, 'scriptwriters': False, 'could': False, 'inject': False, 'unfunny': False, 'kid': False, 'dad': False, 'asshole': False, 'eyelashes': False, 'offers': False, 'smile': False, 'responds': False, 'english': False, 'accent': False, 'attitude': False, 'possibly': False, '_huge_': False, 'beside': False, 'includes': False, 'needlessly': False, 'stupid': False, 'jokes': False, 'olds': False, 'everyone': False, 'shakes': False, 'anyway': False, 'finds': False, 'usual': False, 'reaction': False, 'fluttered': False, 'paves': False, 'possible': False, 'pregnancy': False, 'birth': False, 'gag': False, 'book': False, 'friend': False, 'arnold': False, 'provides': False, 'cacophonous': False, 'funny': False, 'beats': False, 'costumed': False, 'arnie': False, 'dinosaur': False, 'draw': False, 'parallels': False, 'toy': False, 'store': False, 'jeff': False, 'goldblum': False, 'hid': False, 'dreadful': False, 'hideaway': False, 'artist': False, 'fear': False, 'simultaneous': False, 'longing': False, 'commitment': False, 'doctor': False, 'recently': False, 'switch': False, 'veterinary': False, 'medicine': False, 'obstetrics': False, 'joke': False, 'old': False, 'foreign': False, 'guy': False, 'mispronounces': False, 'stereotype': False, 'say': False, 'yakov': False, 'smirnov': False, 'favorite': False, 'vodka': False, 'hence': False, 'take': False, 'volvo': False, 'nasty': False, 'unamusing': False, 'heads': False, 'simultaneously': False, 'groan': False, 'failure': False, 'loud': False, 'failed': False, 'uninspired': False, 'lunacy': False, 'sunset': False, 'boulevard': False, 'arrest': False, 'please': False, 'caught': False, 'pants': False, 'bring': False, 'theaters': False, 'faces': False, '90': False, 'forced': False, 'unauthentic': False, 'anyone': False, 'q': False, '80': False, 'sorry': False, 'money': False, 'unfulfilled': False, 'desire': False, 'spend': False, 'bucks': False, 'call': False, 'road': False, 'trip': False, 'walking': False, 'wounded': False, 'stellan': False, 'skarsg': False, 'rd': False, 'convincingly': False, 'zombified': False, 'drunken': False, 'loser': False, 'difficult': False, 'smelly': False, 'boozed': False, 'reliable': False, 'swedish': False, 'adds': False, 'depth': False, 'significance': False, 'plodding': False, 'aberdeen': False, 'sentimental': False, 'painfully': False, 'mundane': False, 'european': False, 'playwright': False, 'august': False, 'strindberg': False, 'built': False, 'career': False, 'families': False, 'relationships': False, 'paralyzed': False, 'secrets': False, 'unable': False, 'express': False, 'longings': False, 'accurate': False, 'reflection': False, 'strives': False, 'focusing': False, 'pairing': False, 'alcoholic': False, 'tomas': False, 'alienated': False, 'openly': False, 'hostile': False, 'yuppie': False, 'kaisa': False, 'lena': False, 'headey': False, 'gossip': False, 'haven': False, 'spoken': False, 'wouldn': False, 'norway': False, 'scotland': False, 'automobile': False, 'charlotte': False, 'rampling': False, 'sand': False, 'rotting': False, 'hospital': False, 'bed': False, 'cancer': False, 'soap': False, 'opera': False, 'twist': False, 'days': False, 'live': False, 'blitzed': False, 'step': False, 'foot': False, 'plane': False, 'hits': False, 'open': False, 'loathing': False, 'each': False, 'periodic': False, 'stops': False, 'puke': False, 'dashboard': False, 'whenever': False, 'muttering': False, 'rotten': False, 'turned': False, 'sloshed': False, 'viewpoint': False, 'recognizes': False, 'apple': False, 'hasn': False, 'fallen': False, 'tree': False, 'nosebleeds': False, 'snorting': False, 'coke': False, 'sabotages': False, 'personal': False, 'indifference': False, 'restrain': False, 'vindictive': False, 'temper': False, 'ain': False, 'pair': False, 'true': False, 'notes': False, 'unspoken': False, 'familial': False, 'empathy': False, 'note': False, 'repetitively': False, 'bitchy': False, 'screenwriters': False, 'kristin': False, 'amundsen': False, 'hans': False, 'petter': False, 'moland': False, 'fabricate': False, 'series': False, 'contrivances': False, 'propel': False, 'forward': False, 'roving': False, 'hooligans': False, 'drunks': False, 'nosy': False, 'flat': False, 'tires': False, 'figure': False, 'schematic': False, 'convenient': False, 'narrative': False, 'reach': False, 'unveil': False, 'dark': False, 'past': False, 'simplistic': False, 'devices': False, 'trivialize': False, 'conflict': False, 'mainstays': False, 'wannabe': False, 'exists': False, 'purely': False, 'sake': False, 'weak': False, 'unimaginative': False, 'casting': False, 'thwarts': False, 'pivotal': False, 'role': False, 'were': False, 'stronger': False, 'actress': False, 'perhaps': False, 'coast': False, 'performances': False, 'moody': False, 'haunting': False, 'cinematography': False, 'rendering': False, 'pastoral': False, 'ghost': False, 'reference': False, 'certain': False, 'superior': False, 'indie': False, 'intentional': False, 'busy': False, 'using': False, 'furrowed': False, 'brow': False, 'convey': False, 'twitch': False, 'insouciance': False, 'paying': False, 'attention': False, 'maybe': False, 'doing': False, 'reveal': False, 'worthwhile': False, 'earlier': False, 'released': False, '2001': False, 'jonathan': False, 'nossiter': False, 'captivating': False, 'wonders': False, 'disturbed': False, 'parental': False, 'figures': False, 'bound': False, 'ceremonial': False, 'wedlock': False, 'differences': False, 'presented': False, 'significant': False, 'luminous': False, 'diva': False, 'preening': False, 'static': False, 'solid': False, 'performance': False, 'pathetic': False, 'drunk': False, 'emote': False, 'besides': False, 'catatonic': False, 'sorrow': False, 'genuine': False, 'ferocity': False, 'sexually': False, 'charged': False, 'frisson': False, 'during': False, 'understated': False, 'confrontations': False, 'suggest': False, 'gray': False, 'zone': False, 'complications': False, 'accompany': False, 'torn': False, 'romance': False, 'stifled': False, 'curiosity': False, 'thoroughly': False, 'explores': False, 'neurotic': False, 'territory': False, 'delving': False, 'americanization': False, 'greece': False, 'mysticism': False, 'illusion': False, 'deflect': False, 'pain': False, 'overloaded': False, 'willing': False, 'come': False, 'traditional': False, 'ambitious': False, 'sleepwalk': False, 'rhythms': False, 'timing': False, 'driven': False, 'stories': False, 'complexities': False, 'depressing': False, 'answer': False, 'lawrence': False, 'kasdan': False, 'trite': False, 'useful': False, 'grand': False, 'canyon': False, 'steve': False, 'martin': False, 'mogul': False, 'pronounces': False, 'riddles': False, 'answered': False, 'advice': False, 'heart': False, 'french': False, 'sees': False, 'parents': False, 'tim': False, 'roth': False, 'oops': False, 'vows': False, 'taught': False, 'musketeer': False, 'dude': False, 'used': False, 'fourteen': False, 'arrgh': False, 'swish': False, 'zzzzzzz': False, 'original': False, 'lacks': False, 'energy': False, 'next': False, 'hmmmm': False, 'justin': False, 'chambers': False, 'basically': False, 'uncharismatic': False, 'version': False, 'chris': False, 'o': False, 'donnell': False, 'range': False, 'mena': False, 'suvari': False, 'thora': False, 'birch': False, 'dungeons': False, 'dragons': False, 'miscast': False, 'deliveries': False, 'piss': False, 'poor': False, 'ms': False, 'fault': False, 'definitely': False, 'higher': False, 'semi': False, 'saving': False, 'grace': False, 'wise': False, 'irrepressible': False, 'once': False, 'thousand': False, 'god': False, 'beg': False, 'agent': False, 'marketplace': False, 'modern': False, 'day': False, 'roles': False, 'romantic': False, 'gunk': False, 'alright': False, 'yeah': False, 'yikes': False, 'notches': False, 'fellas': False, 'blares': False, 'ear': False, 'accentuate': False, 'annoy': False, 'important': False, 'behind': False, 'recognize': False, 'epic': False, 'fluffy': False, 'rehashed': False, 'cake': False, 'created': False, 'shrewd': False, 'advantage': False, 'kung': False, 'fu': False, 'phenomenon': False, 'test': False, 'dudes': False, 'keep': False, 'reading': False, 'editing': False, 'shoddy': False, 'banal': False, 'stilted': False, 'plentiful': False, 'top': False, 'horse': False, 'carriage': False, 'stand': False, 'opponent': False, 'scampering': False, 'cut': False, 'mouseketeer': False, 'rope': False, 'tower': False, 'jumping': False, 'chords': False, 'hanging': False, 'says': False, '14': False, 'shirt': False, 'strayed': False, 'championing': False, 'fun': False, 'stretches': False, 'atrocious': False, 'lake': False, 'reminded': False, 'school': False, 'cringe': False, 'musketeers': False, 'fat': False, 'raison': False, 'etre': False, 'numbers': False, 'hoping': False, 'packed': False, 'stuntwork': False, 'promoted': False, 'trailer': False, 'major': False, 'swashbuckling': False, 'beginning': False, 'finishes': False, 'juggling': False, 'ladders': False, 'ladder': False, 'definite': False, 'keeper': False, 'regurgitated': False, 'crap': False, 'tell': False, 'deneuve': False, 'placed': False, 'hullo': False, 'barely': False, 'ugh': False, 'small': False, 'annoyed': False, 'trash': False, 'gang': False, 'vow': False, 'stay': False, 'thank': False, 'outlaws': False, '5': False, 'crouching': False, 'tiger': False, 'hidden': False, 'matrix': False, 'replacement': False, 'killers': False, '6': False, 'romeo': False, 'die': False, 'shanghai': False, 'noon': False, 'remembered': False, 'dr': False, 'hannibal': False, 'lecter': False, 'michael': False, 'mann': False, 'forensics': False, 'thriller': False, 'manhunter': False, 'scottish': False, 'brian': False, 'cox': False, 'works': False, 'usually': False, 'schlock': False, 'halfway': False, 'goodnight': False, 'meaty': False, 'substantial': False, 'brilliant': False, 'check': False, 'dogged': False, 'inspector': False, 'opposite': False, 'frances': False, 'mcdormand': False, 'ken': False, 'loach': False, 'agenda': False, 'harrigan': False, 'disturbing': False, 'l': False, 'e': False, '47': False, 'picked': False, 'sundance': False, 'distributors': False, 'scared': False, 'budge': False, 'dares': False, 'speak': False, 'expresses': False, 'seeking': False, 'adolescents': False, 'pad': False, 'bothered': False, 'members': False, 'presentation': False, 'oddly': False, 'empathetic': False, 'light': False, 'tempered': False, 'robust': False, 'listens': False, 'opposed': False, 'friends': False, 'wire': False, 'act': False, 'confused': False, 'lives': False, 'pay': False, 'courtship': False, 'charming': False, 'temptations': False, 'grown': False, 'stands': False, 'island': False, 'expressway': False, 'slices': False, 'malls': False, 'class': False, 'homes': False, 'suburbia': False, 'filmmaker': False, 'cuesta': False, 'uses': False, 'transparent': False, 'metaphor': False, '15': False, 'protagonist': False, 'howie': False, 'franklin': False, 'dano': False, 'reveals': False, 'morbid': False, 'preoccupation': False, 'death': False, 'citing': False, 'deaths': False, 'alan': False, 'j': False, 'pakula': False, 'songwriter': False, 'harry': False, 'chapin': False, 'exit': False, '52': False, 'fascinated': False, 'feelings': False, 'projected': False, 'bright': False, 'move': False, 'force': False, 'complex': False, 'molesters': False, 'beast': False, 'ashamed': False, 'worked': False, 'ill': False, 'advised': False, 'foray': False, 'unnecessary': False, 'padding': False, 'miserable': False, 'bruce': False, 'altman': False, 'seat': False, 'collar': False, 'crime': False, 'degenerate': False, 'youngsters': False, 'kicks': False, 'robbing': False, 'houses': False, 'homoerotic': False, 'shenanigans': False, 'ass': False, 'terrio': False, 'billy': False, 'kay': False, 'handsome': False, 'artful': False, 'dodger': False, 'add': False, 'themes': False, 'suburban': False, 'ennui': False, 'needed': False, 'awkward': False, 'subplots': False, 'concurrently': False, 'relationship': False, 'evenly': False, 'paced': False, 'exceptionally': False, 'acted': False, 'sporting': False, 'baseball': False, 'cap': False, 'faded': False, 'marine': False, 'tattoo': False, 'bluff': False, 'bluster': False, 'quiet': False, 'glance': False, 'withdrawn': False, 'whose': False, 'dramatic': False, 'choices': False, 'broad': False, 'calling': False, 'haley': False, 'restraint': False, 'admirable': False, 'screenplay': False, 'material': False, 'reads': False, 'walt': False, 'whitman': False, 'poem': False, 'moment': False, 'precious': False, 'lingers': False, 'ecstatic': False, 'hearing': False, 'glenn': False, 'gould': False, 'performing': False, 'bach': False, 'goldberg': False, 'variations': False, 'involving': False, 'walter': False, 'masterson': False, 'jealous': False, 'newbie': False, 'thread': False, 'predictably': False, 'leads': False, 'observational': False, 'portrait': False, 'alienation': False, 'royally': False, 'screwed': False, 'terry': False, 'zwigoff': False, 'superb': False, 'confidence': False, 'ambivalent': False, 'typical': False, 'cinema': False, 'wrap': False, 'bullet': False, 'sparing': False, 'writers': False, 'philosophical': False, 'regard': False, 'countless': False, 'share': False, 'blockbuster': False, 'solved': False, 'obstacle': False, 'removed': False, 'often': False, 'extend': False, 'question': False, 'striving': False, 'realism': False, 'destroy': False, 'janeane': False, 'garofalo': False, 'couple': False, 'truth': False, 'cats': False, 'dogs': False, 'excruciating': False, 'matchmaker': False, 'books': False, 'plods': False, 'predestined': False, 'surprises': False, 'jumps': False, 'popular': False, 'political': False, 'satire': False, 'bandwagon': False, 'campaign': False, 'aide': False, 'massacusetts': False, 'senator': False, 'sanders': False, 'reelection': False, 'denis': False, 'leary': False, 'stereotypical': False, 'strategist': False, 'ethics': False, 'scandal': False, 'plagued': False, 'play': False, 'irish': False, 'roots': False, 'boston': False, 'roman': False, 'catholic': False, 'democrat': False, 'contingent': False, 'kennedy': False, 'family': False, 'orders': False, 'ireland': False, 'relatives': False, 'exploit': False, 'soon': False, 'learns': False, 'said': False, 'done': False, 'mantra': False, 'tiny': False, 'misses': False, 'bus': False, 'hotel': False, 'ends': False, 'smallest': False, 'trashiest': False, 'dog': False, 'luggage': False, 'roger': False, 'ebert': False, 'calls': False, 'meet': False, 'happens': False, 'unconventional': False, 'cinematic': False, 'walks': False, 'bathroom': False, 'nude': False, 'sean': False, 'david': False, 'hara': False, 'bathtub': False, 'points': False, 'guessing': False, 'water': False, 'hates': False, 'instant': False, 'saw': False, 'irishman': False, 'hate': False, 'awhile': False, 'succumb': False, 'charms': False, 'happily': False, 'superficial': False, 'detail': False, 'throw': False, 'turmoil': False, 'reconcile': False, 'tune': False, 'annual': False, 'matchmaking': False, 'festival': False, 'lonely': False, 'county': False, 'future': False, 'bliss': False, 'milo': False, 'shea': False, 'snyder': False, 'pops': False, 'onscreen': False, 'spew': False, 'souls': False, 'assured': False, 'match': False, 'utter': False, 'predictability': False, 'message': False, 'respectable': False, 'person': False, 'comedic': False, 'distinction': False, 'sell': False, 'script': False, 'excited': False, 'stays': False, 'stateside': False, 'yelling': False, 'phone': False, 'undoes': False, 'microphone': False, 'speech': False, 'known': False, 'flying': False, 'hong': False, 'kong': False, 'style': False, 'filmmaking': False, 'classics': False, 'nod': False, 'asia': False, 'france': False, 'lukewarm': False, 'dumas': False, 'asian': False, 'stunt': False, 'coordinator': False, 'xing': False, 'xiong': False, 'prior': False, 'attempts': False, 'choreography': False, 'laughable': False, 'van': False, 'damme': False, 'vehicle': False, 'team': False, 'dennis': False, 'rodman': False, 'simon': False, 'sez': False, 'thrown': False, 'air': False, 'result': False, 'tepid': False, 'adventure': False, 'rip': False, 'stinks': False, 'indiana': False, 'jones': False, 'simple': False, 'grandmother': False, 'adapted': False, 'artagnan': False, 'vengeful': False, 'son': False, 'slain': False, 'travels': False, 'paris': False, 'join': False, 'royal': False, 'meets': False, 'cunning': False, 'cardinal': False, 'richelieu': False, 'stephen': False, 'rea': False, 'overthrow': False, 'associate': False, 'febre': False, 'killer': False, 'disbanded': False, 'rounds': False, 'aramis': False, 'nick': False, 'moran': False, 'athos': False, 'jan': False, 'gregor': False, 'kremp': False, 'porthos': False, 'steven': False, 'spiers': False, 'wrongfully': False, 'imprisoned': False, 'leader': False, 'treville': False, 'prison': False, 'frisky': False, 'interest': False, 'chambermaid': False, 'francesca': False, 'footsy': False, 'coo': False, 'hunts': False, 'queen': False, 'captured': False, 'menancing': False, 'forcing': False, 'regroup': False, 'leading': False, 'charge': False, 'peter': False, 'hyams': False, 'wanted': False, 'blend': False, 'eastern': False, 'western': False, 'styles': False, 'disaster': False, 'reality': False, 'ones': False, 'jet': False, 'li': False, 'risk': False, 'ironically': False, 'swordplay': False, 'spread': False, 'carry': False, 'bulk': False, '30': False, 'minute': False, 'picture': False, 'weighs': False, 'monotonous': False, 'gene': False, 'quintano': False, 'prosaic': False, 'wedding': False, 'planner': False, 'mousy': False, 'artangnan': False, 'hyam': False, 'candles': False, 'torches': False, 'grime': False, 'filth': False, '17th': False, 'noted': False, 'standout': False, 'mortal': False, 'kombat': False, 'annihilation': False, 'reviewed': False, 'multiple': False, 'levels': False, 'rampant': False, 'usage': False, 'randian': False, 'subtext': False, 'pervades': False, 'occasionaly': False, 'ironic': False, 'depreciating': False, 'remark': False, 'tosses': False, 'clearly': False, 'marxist': False, 'imagery': False, 'kidding': False, 'seriousness': False, 'fair': False, '*': False, 'necessary': False, 'viewpoints': False, 'watcher': False, 'unfamiliar': False, 'marginally': False, 'fan': False, 'games': False, '1995': False, 'concerned': False, 'martial': False, 'arts': False, 'tournament': False, 'decide': False, 'fate': False, 'billion': False, 'inhabitants': False, 'mortals': False, 'theory': False, 'prevented': False, 'emperor': False, 'shao': False, 'khan': False, 'arriving': False, 'ready': False, 'assumed': False, 'stance': False, 'extraordinarily': False, 'myself': False, 'game': False, 'enjoyed': False, 'directors': False, 'knew': False, 'limitations': False, 'try': False, 'overachieve': False, 'accompanying': False, 'intersperesed': False, 'distracting': False, 'non': False, 'intrusive': False, 'bits': False, 'fluff': False, 'passing': False, 'smashing': False, 'success': False, 'box': False, 'office': False, 'picks': False, 'precisely': False, 'introductory': False, 'exposition': False, 'anyways': False, 'hell': False, 'silly': False, 'rule': False, 'winning': False, 'thereafter': False, 'approximately': False, '85': False, 'alternates': False, 'general': False, 'impression': False, 'producers': False, 'thought': False, 'formula': False, 'volumes': False, 'truly': False, 'sandra': False, 'hess': False, 'sonya': False, 'blade': False, 'execrable': False, 'convince': False, 'loved': False, 'johnny': False, 'greased': False, 'worst': False, 'mis': False, 'james': False, 'remar': False, 'raiden': False, 'thunder': False, 'christopher': False, 'lambert': False, 'japanese': False, 'revered': False, 'chinese': False, 'mystics': False, 'against': False, 'lister': False, 'jr': False, 'president': False, 'u': False, 'fifth': False, 'utility': False, 'totally': False, 'luxury': False, 'amused': False, 'awareness': False, 'introduced': False, 'meaningless': False, 'sidetracks': False, 'including': False, 'muddled': False, 'liu': False, 'kang': False, 'shou': False, 'seeks': False, 'nightwolf': False, 'litefoot': False, 'mystical': False, 'hallucination': False, 'jade': False, 'irina': False, 'pantaeva': False, 'reasons': False, 'unless': False, 'critiques': False, 'apply': False, 'worse': False, 'bridgette': False, 'convincing': False, 'looked': False, 'mimicing': False, 'movements': False, 'choreographer': False, 'knows': False, 'puts': False, 'believable': False, 'jax': False, 'earthquake': False, 'animality': False, 'bonus': False, 'similar': False, 'moves': False, 'mistakenly': False, 'hang': False, 'lamest': False, 'involved': False, 'mud': False, 'wrestling': False, 'lame': False, 'politically': False, 'incorrect': False, 'noticed': False, 'remarked': False, 'upon': False, 'emporer': False, 'perform': False, 'animalities': False, 'motaro': False, 'sheeva': False, 'lifelike': False, 'goro': False, 'enjoy': False, 'femme': False, 'la': False, 'nikita': False, 'backdraft': False, 'sliver': False, 'cindy': False, 'crawford': False, 'anne': False, 'parillaud': False, 'conspire': False, 'shattered': False, 'image': False, 'hooey': False, 'stallone': False, 'stone': False, 'specialist': False, 'poses': False, 'recurring': False, 'assassin': False, 'honeymooning': False, 'jamaica': False, 'believe': False, 'runs': False, 'painful': False, 'pedestrian': False, 'siouxsie': False, 'sioux': False, 'wig': False, 'emotionless': False, 'leather': False, 'clothing': False, 'seattle': False, 'moping': False, 'karen': False, 'endlessly': False, 'complicated': False, 'plots': False, 'helps': False, 'crisp': False, 'modicum': False, 'shakespearean': False, 'begin': False, 'saddled': False, 'leaden': False, 'zero': False, 'breaking': False, 'cardboard': False, 'confines': False, 'insist': False, 'couldn': False, 'huh': False, 'wonderful': False, 'interchange': False, 'charm': False, 'faster': False, 'learned': False, 'cereal': False, 'crybaby': False, 'imagines': False, 'stranger': False, 'sends': False, 'flowers': False, 'chromium': False, 'tough': False, 'nails': False, 'crack': False, 'killing': False, 'machine': False, 'shoots': False, 'mirrors': False, 'stock': False, 'interested': False, 'nest': False, 'egg': False, 'pave': False, 'paradise': False, 'put': False, 'parking': False, 'graham': False, 'greene': False, 'barbet': False, 'schroeder': False, 'reversal': False, 'fortune': False, 'co': False, 'produced': False, 'agonizingly': False, 'b': False, 'york': False, 'vampires': False, 'latest': False, 'opus': False, 'bent': False, 'outing': False, 'aptly': False, 'titled': False, 'suppose': False, 'went': False, 'prefixed': False, 'possessive': False, 'unashamed': False, 'punctuated': False, 'above': False, 'storyline': False, 'borders': False, 'idiotic': False, 'chaotic': False, 'dormant': False, 'martians': False, 'swirling': False, 'gases': False, 'awakened': False, 'meddling': False, 'possess': False, 'hapless': False, 'colonists': False, 'testy': False, 'marilyn': False, 'manson': False, 'lookalikes': False, 'pooh': False, 'bah': False, 'counsel': False, 'official': False, 'melanie': False, 'ballard': False, 'natasha': False, 'henstridge': False, 'sub': False, 'species': False, 'returnee': False, 'officer': False, 'incarcerated': False, 'felon': False, 'second': False, 'blonde': False, 'pulled': False, 'tightly': False, 'awkwardly': False, 'ponytail': False, 'ice': False, 'cube': False, 'appropriately': False, 'named': False, 'pam': False, 'grier': False, 'briefly': False, 'whom': False, 'wonder': False, 'host': False, 'extras': False, 'therefore': False, 'bird': False, 'shots': False, 'sprawling': False, 'metropolis': False, 'reddish': False, 'state': False, 'art': False, 'trademark': False, 'finding': False, 'department': False, 'lock': False, 'laughing': False, 'barrel': False, 'fare': False, 'dingy': False, 'interiors': False, 'cluttered': False, 'exteriors': False, 'inane': False, 'lots': False, 'scarred': False, 'crazed': False, 'aliens': False, 'weaponry': False, 'warfare': False, 'warning': False, 'spontaneously': False, 'stupidly': False, 'villains': False, 'border': False, 'conflicts': False, 'shootouts': False, 'minus': False, 'hissing': False, 'plissken': False, 'miss': False, 'dubbed': False, 'minimalist': False, 'soundtracks': False, 'graduated': False, 'effective': False, 'scoring': False, 'highlighting': False, 'screeching': False, 'guitar': False, 'fortunately': False, 'drowns': False, 'er': False, 'audible': False, 'priceless': False, 'proven': False, 'infertile': False, 'breeding': False, 'ground': False, 'stillborn': False, 'val': False, 'kilmer': False, 'disappointing': False, 'weekend': False, 'overshadowed': False, 'sequels': False, 'among': False, 'pie': False, 'rush': False, 'absent': False, 'references': False, 'set': False, 'perth': False, 'amboys': False, 'closest': False, 'neighbor': False, 'slap': False, 'upside': False, '1': False, 'keeps': False, 'miraculously': False, 'pretend': False, 'means': False, 'intelligent': False, 'grade': False, 'sci': False, 'fi': False, 'singularly': False, 'luck': False, 'starting': False, 'alicia': False, 'silverstone': False, 'beautiful': False, 'creatures': False, 'green': False, 'critic': False, 'large': False, 'choosing': False, 'strikes': False, 'crush': False, 'slow': False, 'moving': False, 'horrific': False, 'adaptation': False, 'clueless': False, 'mailed': False, 'saying': False, 'theater': False, 'expecting': False, 'preview': False, 'crazymadinlove': False, 'whiny': False, 'unlikable': False, 'wasn': False, 'yelled': False, 'f': False, '$&#': False, 'laugh': False, 'agreement': False, 'walked': False, 'babysitter': False, 'inner': False, 'compulsion': False, 'understand': False, 'rent': False, 'regret': False, 'paragraph': False, 'competition': False, 'criticizing': False, 'thin': False, 'shred': False, 'slower': False, 'glacier': False, 'writing': False, 'appeal': False, 'whatsoever': False, 'pointlessly': False, 'concluded': False, 'violent': False, 'plus': False, 'equals': False, 'spends': False, 'twenty': False, 'bubble': False, 'bath': False, 'joined': False, 'four': False, 'features': False, 'settle': False, 'friday': False, 'cocktail': False, 'automatically': False, 'nights': False, 'trods': False, 'discover': False, 'silent': False, 'object': False, 'male': False, 'fantasies': False, 'thinks': False, 'recapture': False, 'youth': False, 'boyfriend': False, 'lets': False, 'wild': False, 'spying': False, 'outside': False, 'prepubescent': False, 'keyhole': False, 'aged': False, 'counterpart': False, 'asked': False, '200': False, 'pound': False, 'silk': False, 'teddy': False, 'fanatasies': False, 'realm': False, 'pg': False, 'imagine': False, 'cinemax': False, 'staple': False, 'absolutely': False, 'pointed': False, 'classify': False, 'mix': False, 'various': False, 'encounters': False, 'third': False, 'space': False, 'odyssey': False, 'apollo': False, 'contact': False, 'hope': False, 'melange': False, 'considering': False, 'disastrous': False, 'results': False, 'sucks': False, 'rescue': False, 'astronauts': False, 'sent': False, '2020': False, 'unknown': False, 'aviators': False, 'visit': False, 'underwhelming': False, 'describe': False, 'uneven': False, 'promise': False, 'buzz': False, 'neutral': False, 'cherry': False, 'colored': False, 'nerdies': False, 'techie': False}\n"
     ]
    }
   ],
   "source": [
    "print((find_features(movie_reviews.words('neg/cv000_29416.txt'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "# rev 대신 our own data를 넣어서 test가 가능함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 13. Naive Bayes Classifier with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npos/neg를 분류하는 text classification algorithm중 하나\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pos/neg를 분류하는 text classification algorithm중 하나\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data\n",
    "training_set = featuresets[:1900]\n",
    "testing_set = featuresets[1900:]\n",
    "# 총 2000개 dataset 95%, 5% split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy percent: 89.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier accuracy percent:\",(nltk.classify.accuracy(classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  justin = True              neg : pos    =      9.8 : 1.0\n",
      "                  annual = True              pos : neg    =      9.5 : 1.0\n",
      "                   sucks = True              neg : pos    =      9.1 : 1.0\n",
      "           unimaginative = True              neg : pos    =      7.8 : 1.0\n",
      "             silverstone = True              neg : pos    =      7.8 : 1.0\n",
      "                 frances = True              pos : neg    =      7.6 : 1.0\n",
      "              schumacher = True              neg : pos    =      7.5 : 1.0\n",
      "                 idiotic = True              neg : pos    =      7.1 : 1.0\n",
      "                  regard = True              pos : neg    =      6.9 : 1.0\n",
      "              uninspired = True              neg : pos    =      6.4 : 1.0\n",
      "                  shoddy = True              neg : pos    =      6.4 : 1.0\n",
      "                    mena = True              neg : pos    =      6.4 : 1.0\n",
      "                  suvari = True              neg : pos    =      6.4 : 1.0\n",
      "               atrocious = True              neg : pos    =      6.3 : 1.0\n",
      "                obstacle = True              pos : neg    =      6.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# justin은 neg label이 pos보다 9.8배 더 출현한다는 것(ratio of occurences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. Saving Classifiers with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n많은 양의 데이터로 학습한 모델을 저장하는 방법\\npickle 모듈을 사용해 저장한 학습 모델 object를 load할 수 있다.\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "많은 양의 데이터로 학습한 모델을 저장하는 방법\n",
    "pickle 모듈을 사용해 저장한 학습 모델 object를 load할 수 있다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "save_classifier = open(\"naivebayes.pickle\",\"wb\")\n",
    "# 파일 객체를 생성\n",
    "# (파일 이름, 모드)\n",
    "pickle.dump(classifier, save_classifier)\n",
    "# (dump할 파일, 덤프할 위치)\n",
    "save_classifier.close()\n",
    "# 열었던 파일의 용도wb가 끝났음을 알려줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# opening using classifier\n",
    "classifier_f = open(\"naivebayes.pickle\", \"rb\")\n",
    "classifier = pickle.load(classifier_f)\n",
    "classifier_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Scikit-Learn Sklearn with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n다른 classifier를 사용하기 위해\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "다른 classifier를 사용하기 위해\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB accuracy percent: 0.87\n",
      "BernoulliNB accuracy percent: 0.89\n"
     ]
    }
   ],
   "source": [
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MultinomialNB accuracy percent:\",nltk.classify.accuracy(MNB_classifier, testing_set))\n",
    "\n",
    "BNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB accuracy percent:\",nltk.classify.accuracy(BNB_classifier, testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes Algo accuracy percent: 89.0\n",
      "Most Informative Features\n",
      "                  justin = True              neg : pos    =      9.8 : 1.0\n",
      "                  annual = True              pos : neg    =      9.5 : 1.0\n",
      "                   sucks = True              neg : pos    =      9.1 : 1.0\n",
      "           unimaginative = True              neg : pos    =      7.8 : 1.0\n",
      "             silverstone = True              neg : pos    =      7.8 : 1.0\n",
      "                 frances = True              pos : neg    =      7.6 : 1.0\n",
      "              schumacher = True              neg : pos    =      7.5 : 1.0\n",
      "                 idiotic = True              neg : pos    =      7.1 : 1.0\n",
      "                  regard = True              pos : neg    =      6.9 : 1.0\n",
      "              uninspired = True              neg : pos    =      6.4 : 1.0\n",
      "                  shoddy = True              neg : pos    =      6.4 : 1.0\n",
      "                    mena = True              neg : pos    =      6.4 : 1.0\n",
      "                  suvari = True              neg : pos    =      6.4 : 1.0\n",
      "               atrocious = True              neg : pos    =      6.3 : 1.0\n",
      "                obstacle = True              pos : neg    =      6.2 : 1.0\n",
      "MNB_classifier accuracy percent: 87.0\n",
      "BernoulliNB_classifier accuracy percent: 89.0\n",
      "LogisticRegression_classifier accuracy percent: 82.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier_classifier accuracy percent: 74.0\n",
      "SVC_classifier accuracy percent: 83.0\n",
      "LinearSVC_classifier accuracy percent: 82.0\n",
      "NuSVC_classifier accuracy percent: 89.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "\n",
    "SVC_classifier = SklearnClassifier(SVC())\n",
    "SVC_classifier.train(training_set)\n",
    "print(\"SVC_classifier accuracy percent:\", (nltk.classify.accuracy(SVC_classifier, testing_set))*100)\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(training_set)\n",
    "print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. Combining Algorithms With NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nensemble 기법을 사용해서 여러 알고리듬을 결합하는 방법\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ensemble 기법을 사용해서 여러 알고리듬을 결합하는 방법\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "    # inherit ClassifierI\n",
    "    \n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "    # returning the most popular vote\n",
    "    \n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf \n",
    "    # return the ration of votes as a confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes Algo accuracy percent: 90.0\n",
      "Most Informative Features\n",
      "                  justin = True              neg : pos    =      9.8 : 1.0\n",
      "                  annual = True              pos : neg    =      9.5 : 1.0\n",
      "                   sucks = True              neg : pos    =      9.1 : 1.0\n",
      "           unimaginative = True              neg : pos    =      7.8 : 1.0\n",
      "             silverstone = True              neg : pos    =      7.8 : 1.0\n",
      "                 frances = True              pos : neg    =      7.6 : 1.0\n",
      "              schumacher = True              neg : pos    =      7.5 : 1.0\n",
      "                 idiotic = True              neg : pos    =      7.1 : 1.0\n",
      "                  regard = True              pos : neg    =      6.9 : 1.0\n",
      "              uninspired = True              neg : pos    =      6.4 : 1.0\n",
      "                  shoddy = True              neg : pos    =      6.4 : 1.0\n",
      "                    mena = True              neg : pos    =      6.4 : 1.0\n",
      "                  suvari = True              neg : pos    =      6.4 : 1.0\n",
      "               atrocious = True              neg : pos    =      6.3 : 1.0\n",
      "                obstacle = True              pos : neg    =      6.2 : 1.0\n",
      "MNB_classifier accuracy percent: 77.0\n",
      "BernoulliNB_classifier accuracy percent: 77.0\n",
      "LogisticRegression_classifier accuracy percent: 80.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier_classifier accuracy percent: 78.0\n",
      "LinearSVC_classifier accuracy percent: 81.0\n",
      "NuSVC_classifier accuracy percent: 80.0\n",
      "voted_classifier accuracy percent: 80.0\n",
      "Classification: pos Confidence %: 100.0\n",
      "Classification: pos Confidence %: 100.0\n",
      "Classification: pos Confidence %: 100.0\n",
      "Classification: pos Confidence %: 100.0\n",
      "Classification: pos Confidence %: 57.14285714285714\n",
      "Classification: pos Confidence %: 100.0\n"
     ]
    }
   ],
   "source": [
    "# modeling\n",
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "\n",
    "\n",
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "# random.shuffle(documents)\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:3000]\n",
    "\n",
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "#print((find_features(movie_reviews.words('neg/cv000_29416.txt'))))\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "        \n",
    "training_set = featuresets[:1900]\n",
    "testing_set =  featuresets[1900:]\n",
    "\n",
    "#classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "classifier_f = open(\"naivebayes.pickle\",\"rb\")\n",
    "classifier = pickle.load(classifier_f)\n",
    "classifier_f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "\n",
    "##SVC_classifier = SklearnClassifier(SVC())\n",
    "##SVC_classifier.train(training_set)\n",
    "##print(\"SVC_classifier accuracy percent:\", (nltk.classify.accuracy(SVC_classifier, testing_set))*100)\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(training_set)\n",
    "print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)\n",
    "\n",
    "\n",
    "voted_classifier = VoteClassifier(classifier,\n",
    "                                  NuSVC_classifier,\n",
    "                                  LinearSVC_classifier,\n",
    "                                  SGDClassifier_classifier,\n",
    "                                  MNB_classifier,\n",
    "                                  BernoulliNB_classifier,\n",
    "                                  LogisticRegression_classifier)\n",
    "\n",
    "print(\"voted_classifier accuracy percent:\", (nltk.classify.accuracy(voted_classifier, testing_set))*100)\n",
    "\n",
    "print(\"Classification:\", voted_classifier.classify(testing_set[0][0]), \"Confidence %:\",voted_classifier.confidence(testing_set[0][0])*100)\n",
    "print(\"Classification:\", voted_classifier.classify(testing_set[1][0]), \"Confidence %:\",voted_classifier.confidence(testing_set[1][0])*100)\n",
    "print(\"Classification:\", voted_classifier.classify(testing_set[2][0]), \"Confidence %:\",voted_classifier.confidence(testing_set[2][0])*100)\n",
    "print(\"Classification:\", voted_classifier.classify(testing_set[3][0]), \"Confidence %:\",voted_classifier.confidence(testing_set[3][0])*100)\n",
    "print(\"Classification:\", voted_classifier.classify(testing_set[4][0]), \"Confidence %:\",voted_classifier.confidence(testing_set[4][0])*100)\n",
    "print(\"Classification:\", voted_classifier.classify(testing_set[5][0]), \"Confidence %:\",voted_classifier.confidence(testing_set[5][0])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17. Investigating bias with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n데이터의 label이 한쪽으로 편향되어 있는 경우,\\ndataset에서 random shuffling을 빼고 모델링하면 매우 낮은 accuracy를 얻는다.\\n이런 경우 label의 비중에 따라 학습에 다른 weight를 주면 도움이 된다.\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "데이터의 label이 한쪽으로 편향되어 있는 경우,\n",
    "dataset에서 random shuffling을 빼고 모델링하면 매우 낮은 accuracy를 얻는다.\n",
    "이런 경우 label의 비중에 따라 학습에 다른 weight를 주면 도움이 된다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18. Improving Training Data for sentiment analysis with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain on a new data set, Twitter sentiment.\\n5300+ / 5300+\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train on a new data set, Twitter sentiment.\n",
    "5300+ / 5300+\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check current working directory\n",
    "import os, nltk, random\n",
    "#os.getcwd()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "short_pos = open(\"short_reviews/positive.txt\",\"r\").read()\n",
    "short_neg = open(\"short_reviews/negative.txt\",\"r\").read()\n",
    "# python3 는 ANSI 형식만 읽을 수 있으므로 저장 시 encoding 방식을 ANSI로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \\n 단위로 split해서 새로운 documents list에 tuple을 append함\n",
    "documents = []\n",
    "for r in short_pos.split('\\n'):\n",
    "    documents.append( (r, \"pos\") )\n",
    "\n",
    "for r in short_neg.split('\\n'):\n",
    "    documents.append( (r, \"neg\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어별로 tokenize한 후, 소문자 변환 이후 FreqDist 계산하여 all_words에 저장\n",
    "all_words = []\n",
    "short_pos_words = word_tokenize(short_pos)\n",
    "short_neg_words = word_tokenize(short_neg)\n",
    "\n",
    "for w in short_pos_words:\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "for w in short_neg_words:\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_features = list(all_words.keys())[:5000]\n",
    "\n",
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "random.shuffle(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-77761a8e2c66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;31m#print((find_features(movie_reviews.words('neg/cv000_29416.txt'))))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[0mfeaturesets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeaturesets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-77761a8e2c66>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;31m#print((find_features(movie_reviews.words('neg/cv000_29416.txt'))))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[0mfeaturesets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeaturesets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-77761a8e2c66>\u001b[0m in \u001b[0;36mfind_features\u001b[1;34m(document)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "        \n",
    "short_pos = open(\"short_reviews/positive.txt\",\"r\").read()\n",
    "short_neg = open(\"short_reviews/negative.txt\",\"r\").read()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for r in short_pos.split('\\n'):\n",
    "    documents.append( (r, \"pos\") )\n",
    "\n",
    "for r in short_neg.split('\\n'):\n",
    "    documents.append( (r, \"neg\") )\n",
    "\n",
    "\n",
    "all_words = []\n",
    "\n",
    "short_pos_words = word_tokenize(short_pos)\n",
    "short_neg_words = word_tokenize(short_neg)\n",
    "\n",
    "for w in short_pos_words:\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "for w in short_neg_words:\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:5000]\n",
    "\n",
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "#print((find_features(movie_reviews.words('neg/cv000_29416.txt'))))\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "# positive data example:      \n",
    "training_set = featuresets[:10000]\n",
    "testing_set =  featuresets[10000:]\n",
    "\n",
    "##\n",
    "### negative data example:      \n",
    "##training_set = featuresets[100:]\n",
    "##testing_set =  featuresets[:100]\n",
    "\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "\n",
    "##SVC_classifier = SklearnClassifier(SVC())\n",
    "##SVC_classifier.train(training_set)\n",
    "##print(\"SVC_classifier accuracy percent:\", (nltk.classify.accuracy(SVC_classifier, testing_set))*100)\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(training_set)\n",
    "print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)\n",
    "\n",
    "\n",
    "voted_classifier = VoteClassifier(\n",
    "                                  NuSVC_classifier,\n",
    "                                  LinearSVC_classifier,\n",
    "                                  MNB_classifier,\n",
    "                                  BernoulliNB_classifier,\n",
    "                                  LogisticRegression_classifier)\n",
    "\n",
    "print(\"voted_classifier accuracy percent:\", (nltk.classify.accuracy(voted_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
